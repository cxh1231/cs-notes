## 1、Redis 简介

`Redis` 是一个 **使用 C 语言开发的数据库**，是一种 `非关系型`（`NoSQL`）**内存键值数据库**。

相比较于传统的数据库，**Redis 的数据存在内存中**，即 `Redis` 是一种 **内存数据库**，所以读写速度非常快，因此 `Redis` 被广泛应用于缓存方向。

`Redis` 除了做缓存之外，也经常用来做分布式锁，甚至是消息队列。

## 2、Redis 数据类型与应用场景

`Redis` 主要有 5 种 **基础数据结构** 和 3 种 **特殊数据结构**：

|   数据类型   |        存储的值        |                         可进行的操作                         |
| :----------: | :--------------------: | :----------------------------------------------------------: |
|   `String`   |  字符串、整数或浮点数  |     字符串：整体或部分执行操作；整数和浮点数：自增、自减     |
|    `List`    |          列表          |           两端读写；N 个元素修剪；范围内的元素保留           |
|    `Hash`    | 包含键值对的无序散列表 |       增、删、查单个键值对；获取全部键值对；判断键存在       |
|    `Set`     |        无序集合        | 增、删、查单个元素；求交、并、差集；随机读元素；判断元素存在； |
|    `Zset`    |        有序集合        | 增、删、查单个元素；根据分值范围或者成员来获取元素；计算某个键的排名 |
|    Bitmap    |        地理位置        |                                                              |
| HyperLogLogs |        基数统计        |                                                              |
|  Geospatial  |         位存储         |                                                              |

> + Redis 的使用场景？在项目中用到了哪些？
> + Redis 的数据类型和底层数据结构？

### 2.1 String（字符串）

#### 简介

`String` 是 Redis 中最简单同时也是最常用的一个数据结构，是一种 **二进制安全的数据结构**，可以用来存储任何类型的数据，比如 **字符串**、**整数**、**浮点数**、**图片**（图片的 base64 编码或者解码或者图片的路径）、**序列化后的对象** 等等。

`String` 的示例，以 `hello` 为 `Key`，以 `world` 为 `Value`：

![image-20220809101317038](https://img.zxdmy.com/2022/202208091013460.png)

#### 应用场景

1、**需要存储常规数据的场景**

- 举例 ：缓存 session、token、图片地址、序列化后的对象（相比较于 Hash 存储更节省内存）。
- 相关命令 ： `SET`、`GET`。

2、**需要计数的场景**

- 举例 ：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。
- 相关命令 ：`SET`、`GET`、 `INCR`、`DECR` 。

```shell
> set hello world
OK
> get hello
"world"
> del hello
(integer) 1
> get hello
(nil)
```

### 2.2 List（列表）

#### 简介

`Redis` 中的 `List` 是 **链表** 数据结构的实现，是一个 **双向链表**，支持正向和反向的查找和遍历，方便操作，不过带来了部分额外的内存开销。

![image-20220809101051718](https://img.zxdmy.com/2022/202208091010047.png)

`List` 的示例，其 `value` 值可以重复：

![image-20220809101305554](https://img.zxdmy.com/2022/202208091013648.png)

#### 应用场景

1、**信息流展示**

- 举例 ：最新文章、最新动态。
- 相关命令 ： `Lpush`、`Lrange`。

```shell
# rpush：从队列右侧插入一个数据
> rpush list-key item
(integer) 1
> rpush list-key item2
(integer) 2
> rpush list-key item
(integer) 3

# 获取列表指定区间的元素，0 表示起始元素，-1 表示最后一个元素
> lrange list-key 0 -1
1) "item"
2) "item2"
3) "item"

# 通过索引值获取元素
> lindex list-key 1
"item2"

# 获取并移出第一个元素
> lpop list-key
"item"

> lrange list-key 0 -1
1) "item2"
2) "item"
```

2、**消息队列**

Redis List 数据结构可以用来做消息队列，只是功能过于简单且存在很多缺陷，不建议这样做。

相对来说，Redis 5.0 新增加的一个数据结构 `Stream` 更适合做消息队列一些，只是功能依然非常简陋。和专业的消息队列相比，还是有很多欠缺的地方比如消息丢失和堆积问题不好解决。

### 2.3 Hash（哈希）

#### 简介

`Redis` 中的 `Hash` 是一个 **String 类型的 field-value（键值对） 的映射表**，特别适合用于存储对象，后续操作的时候，可以直接修改这个对象中的某些字段的值。

![image-20220809101241885](https://img.zxdmy.com/2022/202208091012270.png)

#### 应用场景

1、**对象数据存储场景**

- 举例 ：用户信息、商品信息、文章信息、购物车信息。
- 相关命令 ：`Hset` （设置单个字段的值）、`HMset`（设置多个字段的值）、`Hget`（获取单个字段的值）、`HMget`（获取多个字段的值）

```shell
> hset hash-key sub-key1 value1
(integer) 1
> hset hash-key sub-key2 value2
(integer) 1
> hset hash-key sub-key1 value1
(integer) 0

> hgetall hash-key
1) "sub-key1"
2) "value1"
3) "sub-key2"
4) "value2"

> hdel hash-key sub-key2
(integer) 1
> hdel hash-key sub-key2
(integer) 0

> hget hash-key sub-key1
"value1"

> hgetall hash-key
1) "sub-key1"
2) "value1"
```

### 2.4 Set（集合）

#### 简介

`Redis` 中的 `Set` 类型是一种无序集合，集合中的元素**没有先后顺序但都唯一**，有点类似于 Java 中的 `HashSet` 。

当需要存储一个列表数据，又不希望出现重复数据时，`Set` 是一个很好的选择，并且 `Set` 提供了判断某个元素是否在一个 `Set` 集合内的重要接口，这个也是 `List` 所不能提供的。

![image-20220809101428794](https://img.zxdmy.com/2022/202208091014953.png)

**基于 `Set` 可以轻易实现交集、并集、差集的操作**。

比如你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。这样的话，Set 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。

#### 应用场景

1、**需要存放的数据不能重复的场景**

- 举例：网站 `UV` 统计（数据量巨大的场景还是 `HyperLogLog` 更适合一些）、文章点赞、动态点赞等场景。
- 相关命令：`SCARD`（获取集合数量） 。

![img](https://img.zxdmy.com/2022/202208091015575.png)

2、**需要获取多个数据源交集、并集和差集的场景**

- 举例 ：共同好友（交集）、共同粉丝（交集）、共同关注（交集）、好友推荐（差集）、音乐推荐（差集） 、订阅号推荐（差集+交集） 等场景。
- 相关命令：`SINTER`（交集）、`SINTERSTORE` （交集）、`SUNION` （并集）、`SUNIONSTORE`（并集）、`SDIFF`（交集）、`SDIFFSTORE` （交集）。

![img](https://img.zxdmy.com/2022/202208091015971.png)

3、**需要随机获取数据源中的元素的场景**

- 举例 ：抽奖系统、随机。
- 相关命令：`SPOP`（随机获取集合中的元素并移除，适合不允许重复中奖的场景）、`SRANDMEMBER`（随机获取集合中的元素，适合允许重复中奖的场景）。

### 2.5 Zset（Sorted Set，有序集合）

#### 简介

`Sorted Set` 类似于 Set，但和 Set 相比，`Sorted Set` 增加了一个 **权重参数** `score`，使得集合中的元素能够按 `score` 进行有序排列，还可以通过 `score` 的范围来获取元素的列表。有点像是 Java 中 `HashMap` 和 `TreeSet` 的结合体。

![image-20220809101547131](https://img.zxdmy.com/2022/202208091015570.png)

#### 应用场景

1、**需要随机获取数据源中的元素根据某个权重进行排序的场景**

- 举例 ：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。
- 相关命令 ：`ZRANGE` (从小到大排序) 、 `ZREVRANGE` （从大到小排序）、`ZREVRANK` (指定元素排名)。

### 2.6 Bitmap（位存储）

#### 简介

`Bitmap` 存储的是连续的**二进制数字**（0 和 1），通过 `Bitmap`, 只需要一个 bit 位来表示某个元素对应的值或者状态，`key` 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。

你可以将 `Bitmap` 看作是一个**存储二进制数字（0 和 1）的数组**，数组中每个元素的下标叫做 `offset`（偏移量）。

![image-20220809101645390](https://img.zxdmy.com/2022/202208091016697.png)

#### 应用场景

1、**需要保存状态信息（0/1 即可表示）的场景**

- 举例：用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。
- 相关命令：`SETBIT`、`GETBIT`、`BITCOUNT`、`BITOP`。

### 2.7 HyperLogLog（基数统计）

#### 简介

`HyperLogLog` 是一种有名的**基数计数概率算法** ，基于 `LogLog Counting(LLC)` 优化改进得来，并不是 Redis 特有的，Redis 只是实现了这个算法并提供了一些开箱即用的 API。

Redis 提供的 `HyperLogLog` 占用空间非常非常小，只需要 12k 的空间就能存储接近`2^64`个不同元素。这是真的厉害，这就是数学的魅力么！并且，Redis 对 `HyperLogLog` 的存储结构做了优化，采用两种方式计数：

- **稀疏矩阵** ：计数较少的时候，占用空间很小。
- **稠密矩阵** ：计数达到某个阈值的时候，占用 12k 的空间。

#### 应用场景

1、**数量量巨大（百万、千万级别以上）的计数场景**

- 举例 ：热门网站每日/每周/每月访问 ip 数统计、热门帖子 uv 统计、
- 相关命令 ：`PFADD`、`PFCOUNT`

### 2.8 Geospatial index（地理空间索引）

#### 简介

`Geospatial index`（地理空间索引，简称 `GEO`） 主要用于存储地理位置信息，基于 `Sorted Set` 实现。

通过 `GEO` 我们可以轻松实现两个位置距离的计算、获取指定位置附近的元素等功能。

![image-20220809101829997](https://img.zxdmy.com/2022/202208091018211.png)

#### 应用场景

1、**需要管理使用地理空间数据的场景**

- 举例：附近的人。
- 相关命令: `GEOADD`、`GEORADIUS`、`GEORADIUSBYMEMBER`

## 3、Redis 底层数据结构

![image-20220826154832707](https://img.zxdmy.com/2022/202208261548081.png)

### 3.1 简单动态字符串（SDS）

虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 **简单动态字符串**（`Simple Dynamic String`，`SDS`）。

相比于 C 的原生字符串，Redis 的 `SDS` 不光可以保存文本数据，还可以保存二进制数据，并且获取字符串长度复杂度为 `O(1)`（C 字符串为 O(N)），除此之外，Redis 的 `SDS API` 是安全的，**不会造成缓冲区溢出**。

其定义结构如下：

```c
struct sdshdr{
     //记录 buf 数组中已使用字节的数量，等于 SDS 所保存字符串的长度
     int len;
     
     //记录 buf 数组中未使用字节的数量
     int free;
     
     //字节数组，用于保存字符串
     char buf[];
}
```

![image-20220826155143034](https://img.zxdmy.com/2022/202208261551039.png)

### 3.2 双向链表

Redis 基于 C 定义的 `链表节点` 如下：

```c
typedef struct listNode {
    // 前置节点
    struct listNode *prev;

    // 后置节点
    struct listNode *next;

    // 节点的值
    void *value;

} listNode;
```

![image-20220826155324815](https://img.zxdmy.com/2022/202208261553823.png)

在上面的`链表节点`的基础上， `Redis` 额外定义了一个 list 结构，用来保存该链表的更多信息：

```c
typedef struct list {
    // 表头节点
    listNode *head;

    // 表尾节点
    listNode *tail;

    // 链表所包含的节点数量
    unsigned long len;

    // 节点值复制函数
    void *(*dup)(void *ptr);

    // 节点值释放函数
    void (*free)(void *ptr);

    // 节点值对比函数
    int (*match)(void *ptr, void *key);

} list;
```

示例：一个 list 结构和三个 listNode 结构组成的链表

![image-20220826155539420](https://img.zxdmy.com/2022/202208261555525.png)

+ Redis 的链表，双端，无环；
+ 带有 **表头指针** `head` 和 **表尾指针** `tail`，获取链表的**表头节点**和**表尾节点**的复杂度为 `O(1)` ；
+ 带有 **链表长度计数器** `len`，程序获取链表中**节点数量**的复杂度为 `O(1)` 。

### 3.3 压缩列表

压缩列表（ziplist）是列表键和哈希键的底层实现之一。

当一个列表键只包含少量列表项， 并且每个列表项要么就是小整数值， 要么就是长度比较短的字符串， 那么 Redis 就会使用压缩列表来做列表键的底层实现。

### 3.4 哈希表

`字典` 又称为符号表或者关联数组、或`映射`（`map`），是一种用于**保存键值对的抽象数据结构**。

`Redis` 中定义的 `哈希表`（字典）结构如下：

```c
typedef struct dictht {
    // 哈希表数组
    dictEntry **table;

    // 哈希表大小
    unsigned long size;

    // 哈希表大小掩码，用于计算索引值
    // 总是等于 size - 1
    unsigned long sizemask;

    // 该哈希表已有节点的数量
    unsigned long used;

} dictht;

```

`哈希表节点` 使用 `dictEntry` 结构表示， 每个 `dictEntry` 结构都保存着一个键值对：

```c
typedef struct dictEntry {
    // 键
    void *key;

    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;

    // 指向下个哈希表节点，形成链表，用于解决哈希冲突
    struct dictEntry *next;

} dictEntry;
```

比如有一个大小为 `4` 的`哈希表`，有两个`哈希表节点` `k1` 和 `k2`，其`哈希值`均为 `2`，存在`哈希冲突`，这时，其存储结构如下图所示：

![image-20220826162016723](https://img.zxdmy.com/2022/202208261620404.png)

`Redis` 中的 **字典** 由 `dict` 结构表示：

```c
typedef struct dict {
    // 类型特定函数
    dictType *type;

    // 私有数据
    void *privdata;

    // 哈希表，是数组形式，一般只使用 ht[0]，在 rehash 时，才用 ht[1]
    dictht ht[2];

    // rehash 索引
    // 当 rehash 不在进行时，值为 -1
    int rehashidx; 
    /* rehashing not in progress if rehashidx == -1 */

} dict;
```

对于上面的 类型特定函数，其定义如下：

```c
typedef struct dictType {
    // 计算哈希值的函数
    unsigned int (*hashFunction)(const void *key);

    // 复制键的函数
    void *(*keyDup)(void *privdata, const void *key);

    // 复制值的函数
    void *(*valDup)(void *privdata, const void *obj);

    // 对比键的函数
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);

    // 销毁键的函数
    void (*keyDestructor)(void *privdata, void *key);

    // 销毁值的函数
    void (*valDestructor)(void *privdata, void *obj);

} dictType;
```

最终的完整的字典结构如下图所示：

![image-20220826163044203](https://img.zxdmy.com/2022/202208261630689.png)

### 3.5 跳跃表

跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。

具有如下性质：

1. 由很多层结构组成；
2. 每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；
3. 最底层的链表包含了所有的元素；
4. 如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；
5. 链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；

![image-20220826160949763](https://img.zxdmy.com/2022/202208261609053.png)

### 3.6 整数数组

整数集合（`intset`）是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用集合作为集合键的底层实现。

整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，它可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素。

```c
typedef struct intset {
    // 编码方式
    uint32_t encoding;

    // 集合包含的元素数量
    uint32_t length;

    // 保存元素的数组
    int8_t contents[];

} intset;
```

比如一个包含 5 个 int16_t 类型的整数值的整数集合：

![image-20220826161209221](https://img.zxdmy.com/2022/202208261612171.png)

## 4、Redis 过期与数据淘汰

### 4.1 过期判断

`Redis` 通过一个 **过期字典**（可以看作是 `hash` 表）来保存数据过期的时间。

**过期字典** 的 **键** 指向 `Redis` 数据库中的某个 key（键），过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。

![image-20220809104357687](https://img.zxdmy.com/2022/202208091043071.png)

> 对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。

### 4.2 过期删除策略

Redis 常用的过期数据的删除策略有两个：

| 删除策略 |                  简介                   |                   优劣                   |
| :------: | :-------------------------------------: | :--------------------------------------: |
| 惰性删除 | 在取 key 时才进行过期检查，若过期则删除 | 对CPU友好，但可能造成大量过期 key 未删除 |
| 定期删除 |     间隔一段时间删除一批过期的 key      |  限制删除操作时长和频率减少对CPU的影响   |

定期删除对内存更加友好，惰性删除对 CPU 更加友好，两者各有千秋。

所以 `Redis` 采用的删除策略是 **定期删除+惰性/懒汉式删除** 。

### 4.3 数据淘汰机制

`Redis` 虽然采用了 **定期删除和惰性删除** 的策略，仍有可能漏掉很多过期 `key` 的情况，这就导致大量过期 `key` 堆积在内存里，发生 `Out of Memory` 错误。

可以使用 **Redis 内存淘汰机制** 解决此问题。

Redis 提供 6 种数据淘汰策略，同时在 `Redis 4.0` 增加了两种根据访问频率的删除策略：

|  数据淘汰策略   |                             简介                             |
| :-------------: | :----------------------------------------------------------: |
|  volatile-LRU   | 从 **已设置过期时间** 的数据集中挑选 **最近最少使用** （Least Recently Used）的数据淘汰 |
|  volatile-TTL   | 从 **已设置过期时间** 的数据集中挑选 **将要过期** 的数据淘汰 |
| volatile-random |    从 **已设置过期时间** 的数据集中 **任意** 选择数据淘汰    |
|   allkeys-LRU   |        从 **所有** 数据集中挑选最近最少使用的数据淘汰        |
| allkeys-random  |           从 **所有** 数据集中任意选择数据进行淘汰           |
|   noeviction    |                         禁止驱逐数据                         |
|                 |                      ↓  Redis 4.0新增 ↓                      |
|  volatile-LFU   | 从 **已设置过期时间** 的数据集中挑选 **最不经常使用** （Least Frequently Used）的数据淘汰 |
|   allkeys-LFU   |     从 **所有** 数据集中挑选 **最不经常使用** 的数据淘汰     |

作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。

使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。

## 5、Redis 事件与线程

`Redis` 服务器是一个`事件驱动程序`。

### 5.1 文件事件与单线程（6.0 之前）

**`Redis` 基于 `Reactor` 模式来设计开发了自己的一套高效的`事件处理模型`**，而这个**事件处理模型**对应于 Redis 中的 **文件事件处理器**（File Event Handler），由于**文件事件处理器** 是单线程运行的，所以认为 **Redis 是单线程模型**。

Redis 服务器需要通过 `套接字` 与 `客户端` 或其他服务器进行通信，**文件事件处理器** 就是Redis 对套接字操作的抽象。

**文件事件处理器**（file event handler）主要是包含 4 个部分：

- 多个 socket（客户端连接）
- IO 多路复用程序（支持多个客户端连接的关键）
- 文件事件分派器（将 socket 关联到相应的事件处理器）
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

![image-20220809102823524](https://img.zxdmy.com/2022/202208091028657.png)

Redis 使用 `I/O 多路复用程序` 来同时监听多个`套接字`，并将到达的**事件**传送给 `文件事件分派器`，分派器会根据`套接字`产生的事件类型调用相应的`事件处理器`。

> **I/O 多路复用技术** 的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗。

### 5.2 时间事件

服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。

`时间事件`又分为：

- 定时事件：是让一段程序在指定的时间之内执行一次；
- 周期性事件：是让一段程序每隔指定时间就执行一次。

Redis 将所有时间事件都放在一个`无序链表`中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。

### 5.3 事件的调度与执行

服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。

事件调度与执行由 aeProcessEvents 函数负责，伪代码如下：

```c
def aeProcessEvents():
    # 获取到达时间离当前时间最接近的时间事件
    time_event = aeSearchNearestTimer()
    # 计算最接近的时间事件距离到达还有多少毫秒
    remaind_ms = time_event.when - unix_ts_now()
    # 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设为 0
    if remaind_ms < 0:
        remaind_ms = 0
    # 根据 remaind_ms 的值，创建 timeval
    timeval = create_timeval_with_ms(remaind_ms)
    # 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 决定
    aeApiPoll(timeval)
    # 处理所有已产生的文件事件
    procesFileEvents()
    # 处理所有已到达的时间事件
    processTimeEvents()
```

将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数，伪代码如下：

```c
def main():
    # 初始化服务器
    init_server()
    # 一直处理事件，直到服务器关闭为止
    while server_is_not_shutdown():
        aeProcessEvents()
    # 服务器关闭，执行清理操作
    clean_server()
```

从事件处理的角度来看，服务器运行流程如下：

![image-20220826203731067](https://img.zxdmy.com/2022/202208262037169.png)

### 3.2 多线程（6.0之后）

**Redis 在 4.0 之后的版本中就已经加入了对多线程的支持**，主要是针对一些大键值对的 **删除** 操作的命令，使用其他线程进行异步处理。

大体上来说，**Redis 6.0 之前主要还是单线程处理。**

> 为什么不使用多线程？
>
> 1. 单线程编程容易并且更容易维护；
> 2. Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
> 3. 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

Redis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis 配置文件 `redis.conf` ：

```bash
io-threads-do-reads yes
```

开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 `redis.conf` :

```bash
io-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程
```

> Redis6.0 执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。

## 6、Redis 事务

### 6.1 基本使用

**Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断**。

Redis 可以通过 **`MULTI`，`EXEC`，`DISCARD` 和 `WATCH`** 等命令来实现事务(transaction)功能。

使用 `MULTI` 命令后可以输入多个命令。Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 `EXEC` 命令将执行所有命令。

这个过程是这样的：

1. 开始事务（`MULTI`）。
2. 命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)。
3. 执行事务(`EXEC`)。

通过 `DISCARD` 命令取消一个事务，它会清空事务队列中保存的所有命令。

```
> MULTI
OK
> SET USER "Guide哥"
QUEUED
> GET USER
QUEUED
> EXEC
1) OK
2) "Guide哥"
```

### 6.2 不支持回滚

Redis 的事务和我们平时理解的关系型数据库的事务不同。

Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）。

> 除了不满足原子性之外，事务中的每条命令都会与 Redis 服务器进行网络交互，这是比较浪费资源的行为。
>
> Redis 事务是不建议在日常开发中使用的。

### 6.3  Lua 脚本：解决事务缺陷

Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。

一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。

如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的。因此，严格来说，通过 Lua 脚本来批量执行 Redis 命令也是**不满足原子性**的。

## 7、 Redis 持久化机制

所谓 **持久化数据**，是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。

Redis 两种不同的持久化操作：

|                  持久化                   |                      简介                      |
| :---------------------------------------: | :--------------------------------------------: |
|      快照持久化（Snapshotting，RDB）      |      将某个时间点的所有数据都存放到硬盘上      |
| 只追加文件持久化（Append-Only File，AOF） | 将缓冲区的命令根据同步频率的设置，同步至硬盘中 |

### 7.1 快照持久化（RDB 持久化）

**Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。**

Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。

**快照持久化是 Redis 默认采用的持久化方式**，在 `redis.conf` 配置文件中默认有此下配置：

```shell
save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

### 7.2 只追加文件持久化（AOF 持久化）

与快照持久化相比，`AOF` 持久化的**实时性更好**，因此已成为主流的持久化方案。

默认情况下 Redis 没有开启 `AOF`（append only file）方式的持久化，可以通过 `appendonly` 参数开启。

开启 **AOF 持久化**后，每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到内存缓存 `server.aof_buf` 中，然后再根据 `appendfsync` 配置来决定何时将其同步到硬盘中的 AOF 文件。

在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：

```shell
appendfsync always    # 每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  # 每秒钟同步一次，显式地将多个写命令同步到硬盘
appendfsync no        # 让操作系统决定何时进行同步
```

为了兼顾数据和写入性能，用户可以考虑 `appendfsync everysec` 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度

> AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 `appendonly.aof`。

### 7.3 AOF 重写

AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。

> 该功能是通过读取数据库中的键值对来实现的，程序**无须**对现有 AOF 文件进行任何读入、分析或者写入操作。

### 7.4 持久化机制的优化

Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。

## 8、缓存穿透与缓存雪崩

### 8.1 缓存穿透

#### 简介

大量请求的 key 不存在于缓存中，导致请求直接到了数据库上，没有经过缓存这一层。

#### 解决方案

**1、参数校验**

对一些不合法的参数请求，直接抛出异常信息返回给客户端。

比如查询的数据库 id 不能小于 0、传入的邮箱格式不对。

**2、缓存无效 key**

如果缓存和数据库都查不到某个 key 的数据，就写一个到 Redis 中，并设置过期时间。

> 这种方式可以解决请求的 key 变化不频繁的情况。
>
> 如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。

**3、布隆过滤器**

**布隆过滤器** 是一个数据结构，通过它可以非常方便地判断一个给定数据是否存在于海量数据中。

具体操作：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。

![image-20220809111136868](https://img.zxdmy.com/2022/202208091111471.png)

但可能会误判：

+ **布隆过滤器说某个元素存在，小概率会误判。**
+ **布隆过滤器说某个元素不在，那么这个元素一定不在。**

通过布隆过滤器的原理，可以得出原因：

+ 将元素加入布隆过滤器：
  1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）
  2. 根据得到的哈希值，在位数组中把对应下标的值置为 1
+ 判断是否存在于布隆过滤器：
  1. 对给定元素再次进行相同的哈希计算
  2. 得到值之后判断位数组中的每个元素是否都为 1。如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

所以，一定会出现这样一种情况：**不同的字符串可能哈希出来的位置相同**。

> 可以适当增加位数组大小或者调整我们的哈希函数来降低概率。

### 8.2 缓存雪崩

#### 简介

**缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。**

**有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。**

#### 解决方案

**针对 Redis 服务不可用的情况：**

1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

**针对热点缓存失效的情况：**

1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效。

## 9、Redis 优化

#### bigkey 问题

> 如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 bigkey。

`bigkey` 除了会消耗更多的内存空间，对性能也会有比较大的影响，应尽量避免写入 bigkey。

可以**使用 Redis 自带的 `--bigkeys` 参数来查找bigkey**。

#### 大量 key 集中过期问题

两种常见的方法：

1. 给 key **设置随机过期时间**。
2. 开启 `lazy-free`（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。

## 10、Redis 主从同步

通过主从同步方式配置Redis集群后，当主节点挂掉，运维将从节点升级为主节点即可继续对外提供服务，可以省去中间的恢复原本主节点的时间，提高了可用性。

### 10.1 CAP 与 最终一致

`CAP` 是分布式系统的理论基石：

+ `C` 代表 **一致性** （Consistent）；
+ `A` 代表 **可用性** （Availability）；
+ `P` 代表 **分区容忍性**（Partition tolerance）。

分布式系统一般都是在不同的机器上通过网络进行交互，但是网络一般都会有断开的风险，网络断开的场景一般称之为 **网络分区** 。

当发生 **网络分区** 时，**一致性** 和 **可用性** 很难两全：

+ 发生`网络分区`，两个分布式节点无法通信，其中一个节点的修改操作无法同步到另一个节点中，两个节点中的数据不同，此时数据的 `一致性` 无法满足；
+ 发生`网络分区`，如果要满足 `一致性`，就需要暂停分布式节点对外的服务，等待网络分区恢复，两个节点正常通信数据保持一致后，再对外提供服务，但此时的 `可用性` 将无法满足。

### 10.2 Redis 的最终一致性

Redis 的主从节点之间，数据是异步同步的，所以分布式的 Redis 系统并不符合一致性的要求。

即：主从断开连接，主节点依旧可以正常对外提供服务，所以 Redis 符合的是可用性。

Redis 无法保证实时一致性，为保证 `最终一致性`，`从节点`会努力追赶`主节点`的数据，最终在某个时间数据将和`主节点`相同。

如果发生网络分区，主从数据将不一致。当网络恢复后，`从节点`将会通过`多种同步策略`保证与主节点数据一致。

### 10.2 Redis 同步策略

Redis 持久化有两种方式，一种是全量持久化（RDB），一种是增量持久化（AOF）。

Redis 节点之间同步方式也是两种：`全量同步` 与 `增量同步`。

#### 增量同步

增量备份 是将 Redis 具有修改的指令存储至 AOF 日志中。增量同步与增量备份类似：

`增量同步` 是将 `Redis` 具有修改的指令存在`主节点`本地的内存 `Buffer` 中（一个定长的环形数组），然后`异步`将 `Buffer` 中的指令同步到`从节点`。

`从节点` 通过执行 `主节点` 同步过来的指令流，来达到和 `主节点` 一样的状态，同时向`主节点`反馈自己同步到的位置（偏移量）。

`Buffer` 的内存空间是有限的，无限的指令不会一直存在有限的 Buffer 中。

如果 Buffer 数组满了，将会从头开始覆盖前面的内容。

如果因为网络状况不好，从节点短期内无法和主节点进行同步，当网络状况恢复时，buffer中没有被同步的指令很有可能已经被后续的指令覆盖了，从节点无法通过指令流来进行同步追赶保证一致，这时候就需要快照（全量）同步来保证一致性。

#### 全量同步（快照同步）

`全量同步`与快照备份（RDB）类似，首先 `主节点` 执行一次 `bgsave` 命令，在后台异步保存当前数据库的数据到磁盘，然后将文件传送给`从节点`，从节点接收完毕快照文件后，先将当前内存中的数据清空，然后加载 `快照文件` 中的数据，加载完毕以后通知`主节点`继续进行`增量同步`。

> 在快照同步的过程中，主节点的指令buffer还在不停的增加，如果同步的时间过长或者buffer过小，会导致buffer中的指令被新的指令覆盖，这样快照同步完成后依然无法使用增量同步保证一致，此时将继续发起快照同步，这样会出现死循环的情况。
>
> 因此**需要配置一个合适的buffer大小，保证不会出现指令覆盖，防止出现死循环**。

#### 无盘复制同步

主节点进行快照同步时，将文件保存到本地磁盘是一个很耗时的文件IO操作，如果是非SSD磁盘存储，快照同步对系统的负载会造成较大的影响。

从 `Redis2.8.18` 开始，`Redis` 支持无盘复制，`快照同步`将**不会**进行磁盘操作，生产快照是一个遍历内存的过程，`主节点`一边遍历一边将序列化的内容发送给`从节点`，`从节点`将接收的内容存在磁盘文件中，最后进行一次性加载。

> 当有新的从节点加入时，将进行一次快照同步，后续则是增量同步。

## 11、Redis + MySQL 数据同步问题

#### 采用延时双删处理

- 先删除缓存；
- 再写数据库；
- 休眠500毫秒；
- 再次删除缓存。

#### 异步消息处理



## 11、Redis 集群



