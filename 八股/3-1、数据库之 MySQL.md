> https://javaguide.cn/database/mysql/mysql-questions-01.html
>
> [https://www.javalearn.cn/#/doc/MySQL/面试题](https://www.javalearn.cn/#/doc/MySQL/面试题)

## 1、数据库基础

### 1.1 数据库设计的基本步骤

1. **需求分析** : 分析用户的需求，包括数据、功能和性能需求。
2. **概念结构设计** : 主要采用 E-R 模型进行设计，包括画 E-R 图。
3. **逻辑结构设计** : 通过将 E-R 图转换成表，实现从 E-R 模型到关系模型的转换。
4. **物理结构设计** : 主要是为所设计的数据库选择合适的存储结构和存取路径。
5. **数据库实施** : 包括编程、测试和试运行
6. **数据库的运行和维护** : 系统的运行与数据库的日常维护。

### 1.2 数据库三范式概念

> **`范式`（ Normal Form）**，是英国人 E.F.Codd（关系数据库的老祖宗）在上个世纪70年代提出关系数据库模型后总结出来的，范式是关系数据库理论的基础，也是我们在设计数据库结构过程中所要遵循的规则和指导方法。目前有迹可寻的共有8种范式，依次是：1NF，2NF，3NF，BCNF，4NF，5NF，DKNF，6NF。

通常所用到的只是前三个范式，即：**第一范式（1NF），第二范式（2NF），第三范式（3NF）。**

+ **第一范式（1NF）**：要求属性不能被继续分割，是**数据库最基本的要求**。

  + 比如下面这个表不符合 1NF，将所有属性分解为最基本的属性即可。

    <img src="https://img.zxdmy.com/2022/202207221527511.png" alt="img" style="zoom:67%;" />

+ **第二范式（2NF）**：**消除非主属性对于码的部分函数依赖** ，即在满足 1NF 的前提下，要求表必须有主键，并且没有包含在主键中的列必须完全依赖于主键，不能只依赖于主键的一部分。

  + 比如下面这个表不符合 2NF，主码为【学号，课程号】，而关系模式中存在【姓名】等属性依赖于【学号】的关系，即【姓名】等属性对【学号，课程号】存在部分函数依赖。

    <img src="https://img.zxdmy.com/2022/202207221529500.png" alt="img" style="zoom: 80%;" />

  + 将其转化为如下 2 个表，即可符合 2NF：

    + 学生信息表【学号，姓名，性别，系名，公寓名称】
    + 成绩表【学号，课程号，成绩】

  + *但是，如果一个系一栋或几栋公寓的前提下，上面这种转化方式不符合 3NF。*

+ **第三范式（3NF）**： **消除非主属性对于码的函数依赖** ，即在满足 2NF 的前提下，要求非主键列必须直接依赖于主键，不能存在传递依赖，即不能存在【非主键列 A 依赖于非主键列 B ，非主键列 B 依赖于主键】的情况。

  + 比如一个 订单表【订单ID，订单日期，客户ID，客户名称，客户地址】，其主键是【订单ID】：
    + 订单表中非主键列，均完全依赖于主键【订单ID】，符合 2NF；
    + 但非主键列中存在一种直接依赖关系，即【客户名称，客户地址】直接依赖于【客户ID】；
    + 【客户名称，客户地址】是通过【客户ID】传递依赖于主键【订单ID】，故不符合 3NF。
  + 将其转化为如下 2 个表，即可符合 3NF：
    + 订单表【订单ID，订单日期，客户ID】
    + 客户表【客户ID，客户名称，客户地址】

## 2、MySQL 基本语句

### 2.1 删除语句 drop、delete、truncate 的区别

|          |       delete        |           truncate           |            drop            |
| :------: | :-----------------: | :--------------------------: | :------------------------: |
|   类型   | DML（数据操纵语言） |     DDL（数据定义语言）      |            DDL             |
|   回滚   |       可回滚        |           不可回滚           |          不可回滚          |
|   操纵   |      删除数据       |           清空数据           |          丢弃数据          |
| 删除内容 | 删除全部或部分数据  | 删除全部数据，自增主键初始化 | 删除整个表，以及索引和权限 |
| 删除速度 |    慢，逐行删除     |              快              |            最快            |

> delete 不加 where 子句，作用与 truncate 类似，但主键不初始化。

### 2.2 模糊查询 % 和 \* 通配符的区别

|          |      `*`       |     `%`      |     `_`     |
| :------: | :------------: | :----------: | :---------: |
|   作用   | 匹配所有结果集 | 替代多个字符 | 代替N个字符 |
|  优先级  |  高，优先执行  |      低      |     低      |
| 针对范围 |    所有字段    |   单个字段   |  单个字段   |

> 使用示例：
>
> `select * from user where name like '%三%' or id like '1_';`
>
> 则：`张三`、`张三丰` 等都可以被查询出来，`id` 是 `10`、`19` 的都可以被查询，而 `110` 等则不行。

### 2.3 varchar 和 char 的区别

|          |               char               |                         varchar                          |
| :------: | :------------------------------: | :------------------------------------------------------: |
|   长度   | **定长**，申请的长度即占用字符数 | **变长**，申请的长度是最大长度，实际占用`真实字符长度+1` |
|          |                                  |           最后一个字符存储的是实际占用空间长度           |
| 检索效率 |              效率高              |                                                          |

### 2.4 in 和 exists 的区别

|      |                   in                   |                     exists                     |
| :--: | :------------------------------------: | :--------------------------------------------: |
| 作用 |        把外表和内表作hash 连接         | 对外表作loop循环，每次loop循环再对内表进行查询 |
| 索引 | 内外表都进行全表扫描，**没有用到索引** |      not extsts 的子查询可以用到表的索引       |
| 效率 |                                        |                   一般比较高                   |

### 2.5 SQL 约束

- `NOT NULL`：用于控制字段的内容一定**不能为空**（NULL）。
- `UNIQUE`：控件**字段内容不能重复**，一个表**允许有多个 Unique 约束**。
- `PRIMARY KEY`：**主键**，也是用于控件**字段内容不能重复**，但它在一个表**只允许出现一个**。
- `FOREIGN KEY`：**外键**，用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。
- `CHECK`：用于**控制字段的值范围**。

### 2.6 连接查询

MySQL 的连接查询，通常指将来自多个表的记录行结合起来，然后基于这些表之间的公共字段进行数据拼接。

连接之前，通常确定一个主表作为结果集，然后将其他表的行有选择性的连接至选定的主结果集上。

下面以这两个表演示连接：

![image-20220826111615827](https://img.zxdmy.com/2022/202208261116281.png)

#### 内连接

两张或多张表中同时符合某种条件的数据记录的组合。

```sql
 select 字段 from 表1 inner join 表2 on 表1.字段=表2.字段
```

> 内连接是系统默认的表连接，可以省略 `from` 子句后的 `inner` 关键字。

```sql
SELECT
	* 
FROM
	student
	INNER JOIN college ON student.college_id = college.id
```

运行结果：

![image-20220826111707213](https://img.zxdmy.com/2022/202208261117359.png)

#### 左外连接（左连接）

以**左表**为主根据条件查询右表数据，如果根据条件查询右表数据不存在使用null值填充

```sql
SELECT
	* 
FROM
	student
	LEFT JOIN college ON student.college_id = college.id
```

运行结果：

![image-20220826111854225](https://img.zxdmy.com/2022/202208261118219.png)

#### 右外连接（右连接）

以右表为主根据条件查询左表数据，如果根据条件查询左表数据不存在使用null值填充

```sql
SELECT
	* 
FROM
	student
	RIGHT JOIN college ON student.college_id = college.id
```

执行结果：

![image-20220826112000320](https://img.zxdmy.com/2022/202208261120908.png)

#### 自连接

左表和右表是同一个表，根据连接查询条件查询两个表中的数据。

比如有表：

![image-20220826112642630](https://img.zxdmy.com/2022/202208261126658.png)

SQL：

```sql
SELECT
	* 
FROM
	areas AS c
	INNER JOIN areas AS p ON p.id = c.pid
```

执行结果：

![image-20220826112708585](https://img.zxdmy.com/2022/202208261127129.png)

## 3、存储过程

### 3.1 简介

> **`存储过程`（Stored Procedure）**是在大型数据库系统中，一组为了完成特定功能的SQL 语句集，它存储在数据库中，**一次编译后永久有效，比单纯的SQL速度更快**，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。
>
> **`存储过程`**中可以包含 **逻辑控制语句** 和 **数据操纵语句** , 它可以接受参数 , 输出参数 , 返回单个或多个结果集以及返回值。

### 3.2 存储过程的优缺点

**存储过程的优点**：

1. 存储过程 将复杂的 SQL 语句进行封装，在复杂查询过程中提供了一个替换位置；
2. 存储过程 在创建时即编译并存储在数据库中，其**运行速度比单纯的 SQL 语句更快**；
3. 存储过程 的调用只需要提供存储过程名和必要的参数信息，可以**减少网络流量，减轻网络负担**；
4. 存储过程 可以用于应用程序代码的不同位置，**代码精简一致**；
5. 存储过程 的访问权限（不基于表）可以向不同用户**分别授权**，**数据访问的安全性高**；
6. 存储过程 的参数数据类型，可以通过 SQLParameter 类指定，提高防御；
7. 提高代码安全，方式 SQL 注入。（但未彻底解决 , 例如将数据操作语言 `DML` 附加到输入参数）
8. 存储过程 的更新，比应用程序的更改、测试、部署需要的时间和精力更少，**可维护性高**【有争议】；

**存储过程的缺点**：

1.  难以调试和拓展，更没有拓展性
2.  存储过程 将应用程序绑定到 Server，所以使用存储过程封装业务逻辑将**限制应用程序的可移植性**。

> 《阿里巴巴Java开发手册》中规定，禁止使用存储过程。
>
> 可能原因是，项目的生命周期比较短，人员流动相比于传统的项目更加频繁，在这样的情况下，存储过程的管理确实是没有那么方便，同时，复用性也没有写在服务层那么好。

### 3.3 存储过程的基本使用

**简单存储过程实现：**

创建

```sql
create procedure GetUsers()
begin 
	select * from user; 
end;
```

调用

```sql
call GetUsers();
```

删除

```
drop procedure if exists GetUsers;
```

**带参数的存储过程实现：**

MySql 支持 IN (传递给存储过程) , OUT (从存储过程传出) 和 INOUT (对存储过程传入和传出) 类型的参数 , 存储过程的代码位于 BEGIN 和 END 语句内 , 它们是一系列 SQL 语句 , 用来检索值 , 然后保存到相应的变量 (通过指定INTO关键字) ;

创建

```sql
create procedure GetNameByID(
	in userID int,
	out userName varchar(200)
)
begin
	select name from user
	where id = userID
	into userName;
end;
```

调用

```
call GetNameByID(1, @userName);
select @userName;
```

## 4、数据库引擎

### 4.1  InnoDB 与 MyISAM 的区别

> 在大多数的情况下，**直接选择使用 InnoDB 引擎都是最合适的**，InnoDB 也是 MySQL 的默认存储引擎。

|          |                            InnoDB                            |                            MyISAM                            |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|   事务   |                             支持                             |                            不支持                            |
|   外键   |                             支持                             |                            不支持                            |
| 索引结构 |                            B+ 树                             |                            B+ 树                             |
| 索引数据 | **聚集索引**，数据文件和（主键）索引**绑定**，必须有主键索引，**叶子节点即为数据文件**，主键索引效率很高 | **非聚集索引**，数据文件与索引**分离**，索引保存指向数据文件的**指针** |
| 主键索引 |                            必须有                            |                             可无                             |
| 辅助索引 |      辅助索引需要两次查询，先查主键，再通过主键查询数据      |                  主键索引与辅助索引互相独立                  |
| 全文索引 |                            不支持                            |                 支持，查询效率上 MyISAM 要高                 |
|    锁    |                    支持表、行（默认）级锁                    |                          支持表级锁                          |
|  表行数  |                       不保存，全表扫描                       |                       通过一个变量保存                       |
|   压缩   |                                                              |                    表格可被压缩后进行查询                    |
| 存储文件 |                frm：表定义文件，ibd：数据文件                |        frm：表定义文件，myd：数据文件，myi：索引文件         |
| 应用场景 |            适合频繁修改以及涉及到安全性较高的应用            |                  适合查询以及插入为主的应用                  |

> 为什么 `InnoDB` 没有**行数**这个变量？
>
> 因为 InnoDB 的**事务特性**，在**同一时刻表中的行数对于不同的事务而言是不一样的**，因此count统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。

### 4.2 InnoDB 事务的 ACID 特性保证方式

+ **原子性**：使用 `undo log`（**回滚日志**）来保证；
+ **持久性**：使用 `redo log` （**重做日志**）来保证；
+ **隔离性**：通过 **锁机制**、**MVCC** 等手段来保证（ 默认支持的隔离级别是  `REPEATABLE-READ` ）；
+ **一致性**：保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。

### 4.3 锁机制与 InnoDB 锁算法

**表级锁和行级锁对比：**

- **表级锁：** MySQL 中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。
- **行级锁：** MySQL 中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

**InnoDB 存储引擎的锁的算法有三种：**

- `Record lock`：记录锁，单个行记录上的锁
- `Gap lock`：间隙锁，锁定一个范围，不包括记录本身
- `Next-key lock`：record+gap 临键锁，锁定一个范围，包含记录本身

## 5、MySQL 执行过程

1. **建立连接与权限校验**：**客户端**通过 `TCP` 连接发送连接请求到 `MySQL` **连接器**，**连接器**会对该请求进行**权限验证及连接资源分配**；
2. **查询缓存**：判断缓存是否在哈希表中。在查询命中时，`MySQL` 不会进行解析查询语句，而是**直接使用** SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。
3. **解析与预处理**：即**解析器**通过**词法分析**和**语法分析**验证`SQL`的合法性，并生成**解析树**；**预处理器**则根据 MySQL 规则进一步检查解析树的合法性，以及检查数据表和数据列是否存在，解析别名看是否存在歧义。
4. **优化**：**优化器**负责将语法树转化成执行计划，比如根据 SQL 语句，决定使用哪个索引，或者决定表的连接顺序等。
5. **执行**：**执行器**负责根据执行计划，调用**存储引擎**的API接口来完成整个查询工作。
6. **返回结果**：将执行的结果返回给客户端。如果开启了查询缓存，同时会将数据缓存到查询缓存中。

![image-20220825174256805](https://img.zxdmy.com/2022/202208251742112.png)

![image-20220819200441740](https://img.zxdmy.com/2022/202208192004163.png)

更新语句执行会复杂一点。需要检查表是否有排它锁，写 binlog，刷盘，是否执行 commit。

## 6、MySQL 的锁

### 6.1 锁的简介

当多个用户**并发**地存取数据时，在数据库中就会产生**多个事务同时存取同一数据**的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，**破坏数据库的一致性**。

MySQL 锁的作用：**在多用户环境下保证数据库完整性和一致性**。

MySQL 锁的作用范围：**行** 或 **表**。

### 6.2 锁的宏观分类

|    场景    |                     锁分类                     |
| :--------: | :--------------------------------------------: |
|   粒度上   |             行级锁、表级锁、页级锁             |
|   类别上   |         共享锁（读锁）、排他锁（写锁）         |
| 并发控制上 | 乐观锁（乐观并发控制）、悲观锁（悲观并发控制） |

#### 锁粒度：行级锁与表级锁

关系型数据库中，可以 **按照锁的粒度** 把数据库锁分为**行级锁**、**表级锁** 和 **页级锁**。

|          |       行级锁       |            表级锁            |         页级锁         |
| :------: | :----------------: | :--------------------------: | :--------------------: |
|   简介   | 只对当前操作行加锁 |     对当前操作的整表加锁     | 介于行级锁和表级锁中间 |
| 应用引擎 |       InnoDB       |        InnoDB、MyISAM        |          BDB           |
|   粒度   |        最小        |             最大             |           中           |
|   开销   |         大         |              小              |           中           |
| 加锁速度 |         慢         |              快              |           中           |
|  并发度  |  高，锁冲突概率低  |       低，锁冲突概率高       |   一般，冲突概率中等   |
|   死锁   |       会死锁       |           不会死锁           |         会死锁         |
|   细分   |   共享锁、排他锁   | 共享读锁、独占写锁（排他锁） |           —            |

#### 锁类别：共享锁与排他锁

从 **锁的类别** 上来讲，有 **共享锁** 和 **排他锁**：

|          |    共享锁（Shared Locks，S锁，读锁）    |    排他锁（Exclusive Locks，X锁，写锁、独占锁）     |
| :------: | :-------------------------------------: | :-------------------------------------------------: |
|   简介   |      加共享锁后，只能读，不能改删       |     加排他锁后，可以增、改、删，不允许加任何锁      |
| 应用场景 | 进行数据**读取**时，对数据加 **共享锁** |       进行数据**写入**时，对数据加 **排他锁**       |
| 加锁限制 |        可以同时加**多个 共享锁**        | 只能加**一个 排他锁**，与其他的 排他锁、共享锁 相斥 |

用上面的例子来说就是用户的行为有两种：

+ 一种是来看房，多个用户一起看房是可以接受的。
+ 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。

#### 并发控制：乐观锁与悲观锁

**数据库管理系统**（DBMS）中的 **并发控制** 的任务是确保在多个事务同时存取数据库中同一数据时，不破坏**事务**的**隔离性**和**统一性**，以及**数据库**的**统一性**。

**乐观锁**（乐观并发控制）和**悲观锁**（悲观并发控制）是**并发控制主要采用的技术手段**。

|          |                            乐观锁                            |                            悲观锁                            |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|   简介   | 假设不会发生并发冲突，只在提交操作时检查是否违法数据库的完整性 |    假设一定发生并发冲突，屏蔽一切可能违反数据完整性的操作    |
| 实现方法 |  在修改数据的时候把事务锁起来，通过version的方式来进行锁定   |        在查询完数据的时候就把事务锁起来，直到提交事务        |
| 实现方式 |                    版本号机制 或 CAS算法                     |                        数据库的锁机制                        |
| 应用场景 | **多读场景**：很少发生冲突，使用 **乐观锁** 省去锁的开销，加大系统吞吐量 | **多写场景**：经常发生冲突，导致上层应用不断重试，降低了性能，适合悲观锁 |

### 6.3 锁的微观分类

|           锁名            | 范围 |                             简介                             |
| :-----------------------: | :--: | :----------------------------------------------------------: |
| 意向锁（Intention Locks） | 表锁 |    表明“某个事务正在某些行持有了锁、或该事务准备去持有锁”    |
|  记录锁（Record Locks）   | 行锁 |                      锁住索引记录的一行                      |
|    间隙锁（Gap Locks）    | 行锁 |    锁住一个索引区间（开区间），保证索引区间不会被插入数据    |
| 临键锁（Next-Key Locks）  | 行锁 | Record Lock + Gap Lock，左开右闭区间，唯一属性退化为 Record Lock |
| 自增锁（AUTO-INC Locks）  | 表锁 | 特殊的表级锁，发生涉及AUTO_INCREMENT列的事务性插入操作时产生 |

对于如下的SQL语句：

```sql
update user set name=“hello” where name=“world” and sex="M";
update user set name=“hello” where name=“world”;
```

+ 如果更新条件**没有走索引**，则进行全表扫描，阻止其他任何更新操作，上升为`表锁`；
+ 如果更新条件为**索引字段**，但**并非唯一索引**（含主键索引），则要保证符合条件的记录加上排他锁，并锁定非唯一索引对应的主键索引的值，同时保证锁定区间不能插入新的数据，索引会使用 `临键锁`；
+ 如果更新条件为**索引字段**，并且是**唯一索引**，则降级为 `记录锁`。

### 6.4 死锁与解决方案

数据库的死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

**常见的死锁解决方法**：

+ 对于不同程序并发存取多个表的情况，约定**以相同的顺序访问表**，可以大大降低死锁机会；
+ 在同一个事务中，尽可能做到**一次锁定所需要的所有资源**，减少死锁产生概率；
+ 对于容易产生死锁的业务部分，可以尝试升级锁定颗粒度，通过**表级锁**来减少死锁产生的概率；
+ 如果业务处理不好，可以用 **分布式事务锁** 或者使用**乐观锁**。

### 6.5 锁的优化

- **隔离级别**：尽量使用**较低**的隔离级别；
- **设计索引**：尽量**使用索引去访问数据**，加锁更加精确，从而减少锁冲突；
- **事务大小**：选择合理的事务大小，给记录显示加锁时，最好**一次性请求足够级别的锁**。如修改数据的事务，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁；
- **访问顺序**：不同的程序访问一组表的时候，应尽量**约定一个相同的顺序访问各表**，对于一个表而言，尽可能的**固定顺序的获取表中的行**。这样大大的减少死锁的机会；
- **查询条件**：尽量**使用相等条件访问数据**，这样可以避免间隙锁对并发插入的影响；
- **申请锁**：不要申请超过实际需要的锁级别；
- **使用锁**：数据查询时，非不要不加锁。MySQL 的 MVCC可以实现事务中的查询不用加锁；
- 优化事务性能：MVCC 只在 committed read（读提交）和 repeatable read （可重复读）两种隔离级别下工作；
- 对于特定的事务，可以使用表级锁来提高处理速度，或者减少死锁的可能。

## 7、MySQL 事务

### 7.1 事务简介

**事务是一个不可分割的数据库操作序列**，也**是数据库并发控制的基本单位**，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的**一组操作**，要么都执行，要么都不执行。

转账是事务的典型例子：

假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。

### 7.2 事务的 ACID 特性

> **是逻辑上的一组操作，要么都执行，要么都不执行。**

1. **原子性**（`Atomicity`） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. **一致性**（`Consistency`）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
3. **隔离性**（`Isolation`）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
4. **持久性**（`Durability`）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

### 6.2 并发事务的问题

- **脏读**（Dirty read）：即 `事务A` 正在**访问并修改数据**，在**修改提交至数据库之前**，`事务B` 访问了 `事务A` 修改后的数据。因为 `事务A` 修改的**数据未提交**，`事务B` 读取的数据就是 `脏数据`。如果 `事务A` 发生 **回滚** 操作，则 `事务B` 依据此 `脏数据` 所做的操作是错误的。
- **丢失修改**（Lost to modify）：即 `事务A` 读取了一个数据，`事务B` 也读取了此数据，然后 `事务A` 修改了此数据，之后 `事务B` 也对此数据进行修改，这就导致 `事务A` 的修改结果丢失。
- **不可重复读**（Unrepeatable read）：即 `事务A` 执行过程中，会有多次访问某个数据的过程。在 `事务A` 两次访问某个数据之间，`事务B` 对此数据进行修改，导致 `事务A` 两次读取前后的数据不一致。
- **幻读**（Phantom read）：幻读与不可重复读类似。即 `事务A` 先读取了几行数据，接着 `并发事务B` 插入了一些数据，然后 `事务A` 又进行了查询，会查询到一些原本不存在的记录，就像发生了幻觉一样，故成为幻读。

> 总结：
>
> 脏读是一个事物回滚影响另一个事务；
>
> 不可重复读侧重于修改；
>
> 幻读侧重于新增或删除。

### 6.3 事务的隔离级别与锁关系

#### 隔离级别

> 如何实现事务的隔离？
>
> https://haicoder.net/note/MySQL-interview/MySQL-interview-MySQL-trans-level.html

|      隔离级别（从低到高）      |                简介                | 脏读 | 不可重复读 | 幻读 |
| :----------------------------: | :--------------------------------: | :--: | :--------: | :--: |
| Read Uncommitted（读取未提交） |     允许读取尚未提交的更新数据     |  √   |     √      |  √   |
|  Read Committed（读取已提交）  |   允许读取并发事务已经提交的数据   |  ×   |     √      |  √   |
|  Repeatable Read（可重复读）   | 对同一字段的多次读取结果都是一致的 |  ×   |     ×      |  √   |
|    Serializable（可串行化）    |       所有的事务依次逐个执行       |  ×   |     ×      |  ×   |

详述：

+ `Read Uncommitted`（读取未提交内容）：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。`读未提交` 隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。**读取未提交的数据，也被称之为脏读**（Dirty Read）。

- `Read Committed`（读取提交内容）：这是大多数数据库系统的默认隔离级别（如 Oracle ，但不是 MySQL）。它满足了隔离的简单定义：**一个事务只能看见已经提交事务所做的改变**。**读取已提交的内容，会发生不可重复读**（Nonrepeatable Read）问题，因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一 select 可能返回不同结果。

- `Repeatable Read`（可重复读）：这**是 MySQL 的默认事务隔离级别**，它确保**同一事务的多个实例在并发读取数据时，会看到同样的数据行**。不过理论上，这会导致另一个棘手的问题：**幻读** （Phantom Read）。

- `Serializable`（可串行化）：**通过强制事务排序，使之不可能相互冲突，从而解决幻读问题**。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

总结：

+ **事务隔离机制的实现基于锁机制和并发调度**。其中**并发调度**使用的是`MVVC`（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。
+ **隔离级别越低，事务请求的锁越少**。但 `MySQL` 的`InnoDB` 引擎默认的是 `可重复的` 隔离级别，相比较于 `读已提交` 隔离级别，并不会有任何性能的损失。
+ InnoDB 存储引擎在 `分布式事务` 的情况下一般会用到 **SERIALIZABLE(可串行化)** 隔离级别。

#### 隔离级别与锁关系

|     隔离级别     |                         锁关系                         |
| :--------------: | :----------------------------------------------------: |
| Read Uncommitted |   读取数据不加共享锁，因此与排他锁不冲突（导致脏读）   |
|  Read Committed  |       读取数据加共享锁，语句执行完成后释放共享锁       |
| Repeatable Read  | 读取操作加共享锁，事务提交前不释放，事务执行完毕后释放 |
|   Serializable   |      锁定整个范围的键，并一直持有锁，直至事务完成      |

### 6.4 事务日志与二进制日志

**InnoDB 数据库引擎** 的**事务日志**包含两种：`redo log` 和 `undo log`；还有一种是不属于事务日志的**二进制日志** `bin log`。

+ `undo log` ，指事务开始之前，操作任何数据之前，先将需操作前一个版本的数据备份到一个地方；
+ `redo log` ，指事务中操作的任何数据，将最新的数据备份到一个地方；
+ `bin log` ，记录数据库执行的写入性操作（不包括查询）信息，以二进制的形式保存在磁盘中。

> - 逻辑日志：可以简单理解为记录的就是 SQL 语句；
> - 物理日志：`mysql` 数据最终是保存在数据页中的，物理日志记录的就是数据页变更。

宏观比较：

|             |         undo log         |      redo log       |          bin log           |
| :---------: | :----------------------: | :-----------------: | :------------------------: |
|    定位     |         回滚日志         |      重做日志       |          归档日志          |
|    用途     | 保存事务上一个版本、MVCC | 提升更新性能（WAL） |         数据库重建         |
|  故障恢复   |    保证主库数据原子性    |  保证主库数据一致   |      保证从库数据一致      |
|  所在位置   |       InnoDB 引擎        |     InnoDB 引擎     |        MySQL Server        |
| 写 log 时机 |        事务开始前        |       事务中        |         提交事务时         |
|  log 内容   |         逻辑日志         |     物理页修改      |        原始修改逻辑        |
|  log 空间   |            —             |     持续追加写      |           循环写           |
|   可关闭    |           不可           |        不可         | 单机、无数据重建需求可关闭 |

+ 事务日志的目的：实例或者介质失败，事务日志文件保证提交的记录不丢失，并能继续处理，即 **保证即使数据库发生异常重启，之前提交的记录都不会丢失**。
+ 二进制日志的目的：作主从复制，时间点恢复使用。

#### undo log

`MySQL` 事务的 `原子性` ，底层就是通过 `undo log` 实现的。

`undo log` 主要记录了数据的逻辑变化，其实际是对应 增删改 操作的反操作，比如一条 `INSERT` 语句，对应一条`DELETE` 的 `undo log` ，对于每个 `UPDATE` 语句，对应一条相反的 `UPDATE` 的 `undo log` ，这样在发生错误时，就能回滚到事务之前的数据状态。同时， `undo log` 也是 `MVCC`(多版本并发控制)实现的关键。

**主要作用**

1. 保存了事务发生之前的数据的一个版本，可以用于回滚；
2. 同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读。

**生命周期**

1. **事务开始之前**，将当前事务版本生成 undo log，undo log 也会产生 redo log 来保证 undo log 的可靠性。
2. 当**事务提交之后**，undo log 并不能立马被删除，而是**放入待清理的链表。**
3. 由 **purge 线程**判断是否有其它事务在使用 undo 段中表的上一个事务之前的版本信息，从而决定是否可以清理 undo log 的日志空间。

![image-20220819203837173](https://img.zxdmy.com/2022/202208192038621.png)

**存储内容**

undo log 存储的是逻辑格式的日志，保存了事务发生之前的上一个版本的数据，可以用于回滚。当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着 undo 链找到满足其可见性的记录。

**存储位置**

默认情况下，undo 文件是保存在共享表空间的，也即 ibdatafile 文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的 undo log 信息，这些信息全部保存在共享表空间中，因此共享表空间可能会变得很大，默认情况下，也就是 undo log 使用共享表空间的时候，被“撑大”的共享表空间是不会、也不能自动收缩的。因此，MySQL5.7 之后的“独立 undo 表空间”的配置就显得很有必要了。

**详细示例**

下面是一个 `update undo log` 的一个示例：

1、初始时，某个事务对用户表插入一条记录，如下图所示；

![image-20220824165547017](https://img.zxdmy.com/2022/202208241700926.png)

2、`事务1` 将记录的 `name` 修改为 `Tom`：

+ 在 `事务1` 修改该行(记录)数据时，数据库会先对该行加 `排他锁`；
+ 然后把该行数据拷贝到 `undo log` 中，作为旧记录，即在 `undo log` 中有当前行的拷贝副本；
+ 拷贝完毕后，修改该行 `name` 为 `Tom`，并且修改隐藏字段的 `事务 ID` 为当前 `事务1` 的 `ID`, 我们默认从 1 开始，之后递增，回滚指针指向拷贝到 `undo log` 的副本记录，既表示我的上一个版本就是它；
+ 事务提交后，释放锁。

![image-20220824170047632](https://img.zxdmy.com/2022/202208241700124.png)

3、新的 `事务2` 将记录 `age` 修改为 `30` ：

+ 在 `事务2` 修改该行数据时，数据库也先为该行加锁
+ 然后把该行数据拷贝到 `undo log` 中，作为旧记录，发现该行记录已经有 `undo log` 了，那么最新的旧数据作为链表的表头，插在该行记录的 `undo log` 最前面
+ 修改该行 `age` 为 `30` 岁，并且修改隐藏字段的 `事务 ID` 为当前 `事务2` 的 ID, 那就是 2 ，回滚指针指向刚刚拷贝到 `undo log` 的副本记录
+ 事务提交，释放锁

![image-20220824170407364](https://img.zxdmy.com/2022/202208241704763.png)

通过以上流程可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的 `undo log` 成为一条记录版本线性表，既链表，**undo log 的链首就是最新的旧记录**，链尾就是最早的旧记录（当然就像之前说的该 `undo log` 的节点可能是会 purge 线程清除掉，向图中的第一条 `insert undo log`，其实在事务提交之后可能就被删除丢失了，不过这里为了演示，所以还放在这里）

#### redo log

`redo log` 是物理日志，记录了每次操作在页上做了什么修改。

写 `redo log` 也是需要写磁盘的，但它的好处就是顺序IO，写入的速度很快（比随机IO快很多）。

在 **事务的执行过程中**，便开始写 `redo log`。

**原因**：

+ 传统的在事务提交过程中，将设计修改的数据全部刷新至磁盘的操作方式，存在性能问题；
+ `Innodb` 以 `页` 为单位进行磁盘交互，而一个事务很可能只修改一个数据页里面的几个字节，这种情况，将完整的数据页刷到磁盘的话，浪费资源；
+ 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差

为了保证事务的一致性，以及数据的持久化，因此 `MySQL` 设计了 `redo log` ，只记录事务对数据页做了哪些修改，即可解决性能问题。

> 在 `InnoDB` 中，既有`redo log` 需要刷盘，还有 `数据页` 也需要刷盘， `redo log` 存在的意义主要就是降低对 `数据页` 刷盘的要求。

**日志记录形式**：

`redo log` 采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。

<img src="https://img.zxdmy.com/2022/202208222128015.png" alt="image-20220822205124008" style="zoom:50%;" />

在上图中， `write pos` 表示 `redo log` 当前记录的 `LSN` (逻辑序列号)位置， `check point` 表示 数据页更改记录 刷盘后对应 `redo log` 所处的 `LSN`(逻辑序列号)位置。

`write pos` 到 `check point` 之间的部分是 `redo log` 空着的部分，用于记录新的记录；

`check point` 到 `write pos` 之间是 `redo log` 待落盘的数据页更改记录。

当 `write pos`追上`check point` 时，会先推动 `check point` 向前移动，空出位置再记录新的日志。

启动 `innodb` 的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。

因为 `redo log`记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如 `binlog` )要快很多。

重启`innodb` 时，首先会检查磁盘中数据页的 `LSN` ，如果数据页的`LSN` 小于日志中的 `LSN` ，则会从 `checkpoint` 开始恢复。

还有一种情况，在宕机前正处于`checkpoint` 的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 `LSN` 大于日志中的 `LSN`，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。

**基本流程**：

`redo log` 包括两部分：

+ 内存中的日志缓冲( `redo log buffer` )，
+ 磁盘上的日志文件( `redo log file`)。

`mysql` 每执行一条 `DML` 语句，先将记录写入 `redo log buffer`，后续某个时间点再一次性将多个操作记录写到 `redo log file`。

这种 **先写日志，再写磁盘** 的技术就是 `MySQL`里经常说到的 `WAL(Write-Ahead Logging)` 技术。

在计算机操作系统中，用户空间( `user space` )下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间( `kernel space` )缓冲区( `OS Buffer` )。

因此， `redo log buffer` 写入 `redo logfile` 实际上是先写入 `OS Buffer` ，然后再通过系统调用 `fsync()` 将其刷到 `redo log file`中。

![image-20220822205508770](https://img.zxdmy.com/2022/202208222055119.png)

**具体的落盘策略可以进行配置** 。

`mysql` 支持三种将 `redo log buffer` 写入 `redo log file` 的时机，可以通过 `innodb_flush_log_at_trx_commit` 参数配置，各参数值含义如下：

![image-20220822205801981](https://img.zxdmy.com/2022/202208222058379.png)

- 0：延迟写。不会在事务提交时立即将redo log buffer写入到os buffer，而是每秒写入os buffer，然后立即写入到redo log file，也就是每秒刷盘；
- 1：实时写，实时刷。每次事务提交都会将redo log buffer写入os buffer，然后立即写入redo log file。数据能够及时入盘，但是每次事务提交都会刷盘，效率较低；
- 2：实时写，延时刷。每次事务提交都将redo log buffer写入os buffer，然后每秒将os buffer写入redo log file。

#### bin log

`bin log` 用于记录数据库执行的表结构变更（例如 CREATE、ALTER TABLE）以及表数据修改（INSERT、UPDATE、DELETE）等的写入性操作（不包括查询，如 SELECT 和 SHOW 等）信息，以二进制的形式保存在磁盘中，通过追加的方式进行写入。

`bin log` 是 `MySQL`的逻辑日志，并且由 `Server` 层进行记录，使用任何存储引擎的 `MySQL` 数据库都会记录 `bin log` 日志。可以简单的理解为它存储着每条变更的SQL语句。

MySQL `bin log` 以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的二进制日志是事务安全型的。`bin log` 的主要目的是复制和恢复。

**刷盘时机**：

`mysql` 通过 `sync_binlog` 参数控制 `biglog` 的刷盘时机，取值范围是 `0-N`：

- 0：不去强制要求，由系统自行判断何时写入磁盘；
- 1：每次 `commit` 的时候都要将 `binlog` 写入磁盘（默认）；
- N：每N个事务，才会将 `binlog` 写入磁盘。

**三种模式**

binlog 有三种格式，各有优缺点：

- **statement：** 基于 SQL 语句的模式，某些语句和函数如 UUID, LOAD DATA INFILE 等在复制过程可能导致数据不一致甚至出错。
- **row：** 基于行的模式，记录的是行的变化，很安全。但是 binlog 会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大。
- **mixed：** 混合模式，根据语句来选用是 statement 还是 row 模式。

### 6.5 事务的实现原理

事务是基于 **重做日志文件**(redo log)和 **回滚日志**(undo log)实现的。

+ 每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。

+ 每当有修改事务时，还会产生 `undo log`，如果需要回滚，则根据 undo log 的反向语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。undo log 主要实现数据库的一致性。

## 8、MySQL 索引

### 8.1 索引简介

索引是一种数据结构，是一种文件。

数据库索引，是数据库管理系统中一个排序的数据结构，是一种特殊的文件（InnoDB数据表上的索引是表空间的一个组成部分），它们包含着对数据表里所有记录的引用指针，以协助快速查询、更新数据库表中数据，并占用一定的物理存储空间。

更通俗的说，索引就相当于目录，为了方便查找书中的内容，通过对内容建立索引形成目录。而

### 8.2 索引的优缺点

**优点** ：

- 使用索引可以大大 **加快数据的检索速度**（大大减少检索的数据量）, 这也是创建索引的 **主要原因**；
- 使用索引可以在查询过程中，**使用优化隐藏器**，提供系统性能；
- 通过创建**唯一性索引**，可以保证数据库表中每一行数据的**唯一性**。

**缺点** ：

- **时间方面：创建索引和维护索引需要耗时**。即：当对表中的数据进行增、删、改时，索引需要动态维护，会降低 SQL 的执行效率；
- **空间方面：索引需要占用物理文件存储**，也会耗费一定空间。

### 8.3 索引的底层数据结构

#### Hash 索引

基于哈希表实现，只有精确匹配索引所有列的查询才有效。

对于每一行数据，存储引擎都会对所有的索引列计算一个**哈希码**（hash code），并且Hash索引将所有的**哈希码**存储在索引中，同时在索引表中保存指向每个数据行的指针。

![image-20220819201418648](https://img.zxdmy.com/2022/202208192014972.png)

> **为什么MySQL 没有使用 Hash 作为索引的数据结构？**
>
> + **Hash 冲突问题**：哈希表存在哈希冲突问题；
> + 最大缺点：**Hash 索引不支持顺序和范围查询**，使得对表数据进行排序或范围查询时，索引不可用。

#### B 树索引

`B-Tree` 能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，**数据分布在各个节点之中**。

![image-20220819201836182](https://img.zxdmy.com/2022/202208192018448.png)

但 MySQL 并没有采用这种索引结构。

#### B\+ 树索引（实际应用）

**B\+ 树的数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址**。

![image-20220819201946478](https://img.zxdmy.com/2022/202208192019737.png)

相对于 `B-Tree` ，`B+Tree` 进行范围查找时，只需要查找两个节点，进行遍历即可。而 `B-Tree` 需要获取所有节点，相比之下 `B+Tree` 效率更高。

`B-Tree` 的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 `B+Tree` 的检索效率就很稳定了，**任何查找都是从根节点到叶子节点的过程**，叶子节点的顺序检索很明显。

**B+ 树的性质**：

- n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
- 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
- B+ 树中，数据对象的插入和删除仅在叶节点上进行。
- B+ 树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。

#### 为什么索引结构默认使用B+Tree

**相比较于B-tree，B+Tree的优点**：

- **B+树的磁盘读写代价更低**：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B(B-)树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对`IO读写次数就降低`了。
- 由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在`区间查询`的情况，所以通常B+树用于数据库索引。

**Hash的不足**：

- 虽然可以快速定位，但是没有顺序，IO复杂度高；

- 基于Hash表实现，只有Memory存储引擎显式支持哈希索引 ；
- 适合**等值查询**，如=、in()、<=>，不支持范围查询 ；
- 因为不是按照索引值顺序存储的，就不能像B+Tree索引一样利用索引完成[排序](https://www.javalearn.cn/#/) ；
- Hash索引在查询等值时非常快 ；
- 因为Hash索引始终索引的**所有列的全部内容**，所以不支持部分索引列的匹配查找 ；
- 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 。

**二叉树的不足**： 树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。

**红黑树的不足**： 树的高度随着数据量增加而增加，IO代价高。

### 8.4 索引的分类

|         分类角度         |                          索引名称                          |
| :----------------------: | :--------------------------------------------------------: |
|         存储结构         | `B-TREE 索引`、`Hash 索引`、`FULL TEXT索引`、`R-TREE 索引` |
|         应用层次         | `普通索引`、`唯一索引`、`联合索引`（复合索引）、`主键索引` |
|           键值           |             `主键索引`、`辅助索引`（二级索引）             |
| 键值的逻辑关系与存储关系 |     `聚集索引`（聚簇索引）、`非聚集索引`（非聚簇索引）     |

#### 存储结构上的分类

`MySQL` 的索引在**存储结构**（存储时保存的形式）上主要分为 `B Tree 索引`（B-Tree或B+Tree索引）、`Hash 索引`、`全文索引`（Full-Text Search）、`R-Tree 索引` 四种类别。

前两种存储结构前文有讲述。

**全文索引**：

**全文索引**（`FULLTEXT`）是针对使用 `like '%xxx%'` 进行模糊查询时的优化。

全文索引（`Full-Text Search`）是将存储于数据库中的整本书或整篇文章中的任意信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种统计和分析。

**全文索引** 一般是通过 **倒排索引** 实现的，在 `辅助表` 中存储了单词与单词自身在一个或多个文档中所在位置之间的映射，这通常利用关联数组实现，拥有两种表现形式：

+  inverted file index：{单词，单词所在文档的id}
+  full inverted index：{单词，（单词所在文档的id，再具体文档中的位置）}

#### 应用层次上的分类

`MySQL` 的索引在 **应用层次** 上主要分为 `普通索引`、`唯一索引`、`主键索引`、`联合索引`（复合索引） 几类。

| 索引名称 |                           简介                           |    关键字    |
| :------: | :------------------------------------------------------: | :----------: |
| 普通索引 |  一个索引只包含单个列，一个表可以有多个单列索引，无限制  |    index     |
| 联合索引 | 多列值组成一个索引，专门用于组合搜索，其效率大于索引合并 |    index     |
| 唯一索引 |             索引列的值必须唯一，但允许有空值             | unique index |
| 主键索引 |    特殊的唯一索引，不允许有控制，添加主键约束即可实现    | primary key  |

**普通索引**：

```sql
create index <索引的名称> on tablename(字段名);
alter table <表名> add index [索引的名字]（字段名）;
create table 表名([...], index [索引的名字](字段名));
```

**唯一索引**：

唯一索引是普通索引的升级版本，索引字段必须是唯一的，但允许有空值。

在创建或修改表时，追加唯一约束，就会自动创建对应的唯一索引。

```sql
create unique index 索引名 on 表名(字段名);
alter table 表名 add unique index 索引名(字段名);
create table 表名([...], unique 索引名(字段名));
```

**主键索引**：

主键索引是一种特殊的唯一索引，因为它不允许有空值。在创建和修改表的时候，追加主键约束即可，每一个表只能有一个主键。

```sql
create table 表名([...], primary key(字段名));
alter table 表名 add primary key(字段名);
```

**联合索引**：

联合索引可以代替多个普通索引，并且开销比多个普通索引更小。

联合索引又分 `宽索引`和`窄索引`：

+ **窄索引** 一般指的是作用在1~2列的索引，一般推荐使用窄索引。
+ **宽索引** 就是作用在2列以上的索引。

```sql
create index 索引名 on 表名(字段1，字段2，...);
alter table 表名 add index 索引名(字段1，字段2，...);
create table 表名 ([...], index 索引名(字段1， 字段2， ...));
```

MySQL 的 **联合索引** 有一个 **最左匹配（最左优先）原则**。

即：在 `where` 子句进行等值查找（如 `=` 和 `in`）时，MySQL 会根据索引，一直向右匹配，直至遇到范围查找（>、<、between、like 等）才停止匹配。

比如有索引`(a,b,c)`，有以下查询：

+ `where a = 1` ：只走了 `(a)` 索引；
+ `where a = 1 and c = 3` ：只走了 `(a)` 索引；
+ `where a = 1 and c = 3 and b = 2` ：走了索引`(a,b,c)`，等值查找的顺序任意，查询优化器会优化成索引可以识别的形式；
+ `where a = 1 and b > 2 and c = 3` ：只走了索引 `(a)`
+ `where a = 1 and c > 3 and b = 2` ：只走了索引 `(a,b)`

因此在建立联合索引时，应注意索引列的顺序。

一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。

#### 键值的逻辑关系与存储关系上的分类

>

`MySQL` 的索引在 **键值的逻辑关系与存储关系** 上主要分为 `聚集索引`（聚簇索引）和`非聚集索引`（非聚簇索引）两类，它们并非单独的索引类型，而是一种数据存储方式。

|   类别   |     `聚集索引`（聚簇索引，主键索引）      |    `非聚集索引`（非聚簇索引、二级索引）     |
| :------: | :---------------------------------------: | :-----------------------------------------: |
|   简介   | `B-Tree索引`  中保存了 `主键` 和 `数据行` | `B+Tree索引` 的叶子节点只存储了 `主键的值`  |
| 应用引擎 |            InnoDB（主键索引）             | InnoDB（二级索引）、MyISAM（主键+二级索引） |

> 主要区别就是：叶子节点存储的是表中的全部数据，还是对应的主键（行号）。

比如有如下的数据表（不止这三列，只是这三列有索引）：

<img src="https://img.zxdmy.com/2022/202208232002723.png" alt="image-20220823200253022" style="zoom:67%;" />

`id` 为`主键索引` ；`name`和`age`为`普通索引`，也就是 `二级索引`，也就是`非聚集索引`。

所以对于 `id` 来说，其在磁盘中的存储结构是 `聚集索引`，如下图所示：

<img src="https://img.zxdmy.com/2022/202208232009762.png" alt="image-20220823200929100" style="zoom:67%;" />

对于 `name` 来说，其在磁盘中的存储结构是 `非聚集索引`，如下图所示：

<img src="https://img.zxdmy.com/2022/202208232009064.png" alt="image-20220823200956080" style="zoom:67%;" />

### 8.5 索引与回表

对于 `InnoDB` 来说，通过 `二级索引` 查询时，需要先根据 `聚集索引`（主键索引）查找到记录的 `聚集索引键`，再根据 `聚集索引` 查询 `数据行`。这个过程，称之为 **回表**。

第一次索引一般是**顺序IO**，回表的操作属于**随机IO**。需要回表的次数越多，即随机IO次数越多，我们就越倾向于使用全表扫描 。

通常情况下， 主键索引（聚簇索引）查询只会查一次，而非主键索引（非聚簇索引、二级索引）需要回表查询多次。

但是：**非聚簇索不一定会回表查询**。如果查询语句需要查询的字段，全部命中了索引，则不需要进行回表查询。

> 一个索引包含（覆盖）所有需要查询字段的值，被称之为"覆盖索引"。

### 8.6 前缀索引

> https://blog.csdn.net/weixin_38192427/article/details/122884032

当需要根据一个`长字符串类型`进行查找时，比如身份证、邮箱，为了避免全表扫描，需要为该`字符串字段`添加索引。

通即：对文本的前几个字符建立索引（具体是几个字符在建立索引时指定），这样建立起来的索引更小，所以查询更快。

1、计算**完整列**的索引选择性：

**索引选择性**：指`不重复的索引值`和数据表的`记录总数`的`比值`，取值范围在 `[0,1]` 之间。

```sql
SELECT COUNT(DISTINCT column_name) / COUNT(*) FROM table_name;
```

索引的选择性越高，则查询效率越高，因为选择性高的索引可以让 `MySQL` 在查找时过滤掉更多的行。

但当`索引选择性` 达到 `1` 时，就成了 `唯一索引` ，浪费空间，不符合创建 前缀索引 的初衷。

2、计算**不同前缀长度**的索引选择性：

```sql
SELECT COUNT(DISTINCT LEFT(column_name, prefix_length)) / COUNT(*) FROM table_name;
```

多次运行此语句，通过设置合适的 `prefix_length`，直至计算结果**最接近于全列选择性的时候**，就是最佳结果。

3、创建前缀索引

```sql
alter table table_name add index index_name(column_name(best_prefix_length));
```

> 注意：`order by` 不支持前缀索引。

### 8.7 索引下推

`MySQL 5.6` 引入了 **索引下推优化**，在 InnoDB 中只针对二级索引有效。

索引下推是默认开启的，使用如下命令可以关闭：

```sql 
SET optimizer_switch = ‘index_condition_pushdown=off’;
```

有了索引下推优化，可以 **减少回表次数**。比如：

在 `people_table`中有一个二级索引`(zipcode，lastname，address)`，有如下查询：

```sql
SELECT
	* 
FROM
	people 
WHERE
	zipcode = '95054' 
	AND lastname LIKE '%etrunia%' 
	AND address LIKE '%Main Street%';
```

**没有使用索引下推技术**：

+ 首先 MySQL 通过 `zipcode='95054'` 从存储引擎中查询对应的数据，返回到MySQL服务端；
+ 然后 `MySQL 服务端` 基于 `lastname LIKE '%etrunia% and address LIKE '%Main Street%'` 来判断数据是否符合条件。

**使用索引下推技术**：

+ 首先 MYSQL 返回符合 `zipcode=’95054’` 的 `索引`；
+ 然后根据条件 `lastname LIKE '%etrunia% and address LIKE '%Main Street%'` 来判断索引是否符合：
  + 如果符合条件，则根据该索引来定位对应的数据；
  + 如果不符合，则直接reject掉。

### 8.8 索引失效

索引在以下情况会导致索引失效（不走索引）：

|                索引失效情况                 |                  示例                  |
| :-----------------------------------------: | :------------------------------------: |
|          使用不等于：`!=` 或 `<>`           |            WHERE age <> 18             |
|     索引列使用 `OR`（连接相同字段除外）     |      WHERE id = 1 OR name= "张三"      |
|         索引列类型不一致（字符串）          |           WHERE name = 2345            |
|               索引列使用函数                | WHERE DATE(create_time) = '2020-09-03' |
| 索引列 `LIKE` 查询以 `%` 开头（放后边才走） |         WHERE name LIKE "%三"          |
|       索引列参与计算（+，-，*，/，!）       |          WHERE age - 1 = 20;           |
|             NOT IN、NOT EXISTS              |                                        |

### 8.9 创建索引的注意事项

1. 选择合适的字段：
  1. 不为NULL的字段 , 如果需要 , 使用0 , 1 , true , false来代替，因为含有空值的列很难进行查询优化；
  2. 被频繁查询的字段；
  3. 被作为条件查询的字段；
  4. 频繁需要排序的字段；
  5. 频繁连接的字段；
2. 被频繁更新的字段应谨慎建立索引；
3. 满足最左前缀匹配原则；
4. 选择区分度高（字段不重复的比例）的列作为索引，扫描的记录数越少，唯一键的区分度是1；
5. 索引列不能参与计算，保持列“干净”；
6. 尽量扩展索引，不要新建索引。如表中已有索引 `(a)`，需要添加 b 列，则修改 `(a)` 为 `(a,b)`；也即：尽量考虑联合索引而非单列索引；
7. 尽量避免冗余索引：能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引
8. 索引字段越小越好：数据库的数据存储以页为单位，一页存储的数据越多，一次IO操作获取的数据越大效率越高。

## 9、MySQL 的 MVCC（多版本并发控制）

### 9.1 MVCC 的简介

`MVCC`（Multi-Version Concurrency Control，多版本并发控制）是一种并发控制的方法，一般**在数据库管理系统中实现对数据库的并发访问**，**在编程语言中实现事务内存**。

`MVCC` 在 InnoDB 引擎的 MySQL 数据库中的实现，主要是为了**提高数据库并发性能**，用更好的方式去处理读-写冲突，做到**即使有读写冲突时，也能做到不加锁，非阻塞并发读**。

大多数的 MySQL 事务型存储引擎（InnoDB）所采用的并非简单的行锁机制，而是与 MVCC 一起使用。

锁机制可以控制并发操作，但系统开销大。

而 MVCC 可以在多数情况下代替行级锁，能够降低系统开销。

### 9.2 MVCC 的相关概念

#### 当前读与快照读

|       |                   当前读（锁定读）                   |     快照读（一致性非锁定读）     |
| :---: | :--------------------------------------------------: | :------------------------------: |
| 简介  |             读取的是记录的 **最新版本**              |  读取的记录 **可能是历史版本**   |
|  锁   |     读取时加锁，保证其他并发事务不能修改当前记录     | 不加锁，基于 `MVCC` 实现并发控制 |
|       |                                                      |       隔离级别不能是串行化       |
| 示例1 |        select lock in share mode (`共享锁`),         |       不加锁的 select 操作       |
| 示例2 | select for update; update; insert; delete (`排他锁`) |                                  |

> **MVCC 就是为了实现 `读-写冲突不加锁`，而这个`读`指的就是`快照读`, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现**

但是：

+ MVCC 是一个抽象概念，即 **维持一个数据的多个版本，使得读写操作没有冲突**，并非具体实现；
+ **快照读就是 MySQL 实现 MVCC 理想模型的其中一个非阻塞读功能**；
+ MVCC 模型在 MySQL 中的具体实现则是由 **`3 个隐式字段`**，**`undo 日志`** ，**`Read View`** 等去完成的。

#### 数据库并发场景

- `读-读`：不存在任何问题，也不需要并发控制；
- `读-写`：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读；
- `写-写`：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失；

> + 第一类更新丢失：`事务A` 撤销时，把已经提交的 `事务B` 的更新数据覆盖了。
> + 第二类更新丢失：`事务A` 覆盖了 `事务B` 已经提交的数据，造成 `事务B` 所做的操作丢失。

### 9.3 MVCC 解决的问题

多版本并发控制（`MVCC`）是一种用来解决 `读-写冲突` 的 `无锁并发控制`，也就是为**事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照**。

所以 MVCC 可以为数据库解决以下问题：

+ 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能
+ 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题

所以在实际应用中，通常采用下面的两种组合来处理`读-写冲突`和`写-写冲突`：

- `MVCC + 悲观锁`：MVCC 解决读写冲突，悲观锁解决写写冲突
- `MVCC + 乐观锁`：MVCC 解决读写冲突，乐观锁解决写写冲突

### 9.4 MVCC 的三个概念

`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log** 。

在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改。

在 MVCC 的实现方式中，主要有3个概念：

#### 隐式字段

每行记录除了我们自定义的字段外，还有数据库隐式定义的 `DB_TRX_ID`, `DB_ROLL_PTR`, `DB_ROW_ID` 等

|         字段名         |      名称       |                         简介                         |
| :--------------------: | :-------------: | :--------------------------------------------------: |
|  `DB_TRX_ID`（6字节）  | 最近修改事务 ID |         记录 `创建/最后修改` 该记录的事务 ID         |
| `DB_ROLL_PTR`（7字节） |    回滚指针     |               指向这条记录的上一个版本               |
|  `DB_ROW_ID`（6字节）  |  隐含的自增 ID  | 未设置主键，InnoDB 会自动以 `DB_ROW_ID` 创建聚簇索引 |

示例图：

![image-20220824161642974](https://img.zxdmy.com/2022/202208241700907.png)

#### undo log

`undo log` 的相关概念在 [事务章节](#undo log) 已经做了详细的介绍。

`undo log` 主要分为两种：

|      |            insert undo log            |          update undo log（MVCC 实际有用的）           |
| :--: | :-----------------------------------: | :---------------------------------------------------: |
| 简介 | 事务在 insert 新记录时产生的 undo log |     事务在进行 update 或 delete 时产生的 undo log     |
| 需要 |          只在事务回滚时需要           |               在事务回滚、快照读时需要                |
| 删除 |       事务提交后可以被立即丢弃        |                     不能随便删除                      |
|      |                                       | 当快速读或事务回滚不涉及该日志时，才被 purge 线程清除 |

#### Read View（读视图）

所谓 `Read View`，指的是 **事务进行快照读 (select * from) 操作时，生产的`读视图`**（Read View）。

即：

+ 当隔离级别是`RR`（可重复读）时，每开启一个事物，系统会给该事务分配一个 `事物ID`；
+ 当该事务执行 `SELECT` 语句时，会生成一个当前时间点的 `事务快照 ReadView`。

对于每个事务的快照读 ReadView，核心属性如下：

+ `m_ids` ：生成该 ReadView 时，当前系统中活跃读写事务（还未执行提交的事务）的`事务ID列表`；
+ `m_up_limit_id` ：生成该 ReadView 时，当前系统中活跃的读写事务中`最小的事务ID`（小于这个 ID 的数据版本均可见）；
+ `m_low_limit_id` ：生成该 ReadView 时，系统应该分配给`下一个事务的ID值`（目前出现过的最大的事务 ID+1）；
+ `m_creator_trx_id` ：生成该 ReadView 的 `事务ID`（创建该 ReadView 的事务ID）

ReadView 主要是用来做`可见性判断`，里面保存了 “当前对本事务不可见的其他活跃事务”

即当某个事务执行快照读的时候，对该记录创建一个`Read View 读视图`，把它比作条件用来**判断当前事务能够看到哪个版本的数据**，既可能是当前最新的数据，也有可能是该行记录的 `undo log` 里面的某个版本的数据。

### 9.5 MVCC 的实现原理：数据可见性算法

在 `InnoDB` 存储引擎中，创建一个新事务后，执行每个 `select` 语句前，都会创建一个快照（Read View），**快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号**。

其实简单的说保存的是系统中当前**不应该被本事务看到的其他事务 ID 列表**（即 `m_ids`）。

当用户在这个事务中要读取某个记录行的时候，`InnoDB` 会将该记录行的 `DB_TRX_ID` 与 `Read View` 中的一些变量及当前事务 ID 进行比较，**判断是否满足可见性条件**。

**具体的比较算法**：

![image-20220825170059881](https://img.zxdmy.com/2022/202208251701360.png)

**事务可见性示意图**：

![image-20220825165526503](https://img.zxdmy.com/2022/202208251655824.png)

**数据可见性算法流程**：

1. 如果记录 `DB_TRX_ID < m_up_limit_id` ，表明最新修改该行的事务（`DB_TRX_ID`）在当前事务创建快照之前就提交了，所以该记录行的值对当前事务是可见的
2. 如果 `DB_TRX_ID >= m_low_limit_id`，那么表明最新修改该行的事务（`DB_TRX_ID`）在当前事务创建快照之后才修改该行，所以该记录行的值对当前事务不可见。跳到步骤 5
3. `m_ids` 为空，则表明在当前事务创建快照之前，修改该行的事务就已经提交了，所以该记录行的值对当前事务是可见的
4. 如果 `m_up_limit_id <= DB_TRX_ID < m_low_limit_id`，表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表 `m_ids` 进行查找（源码中是用的二分查找，因为是有序的）
  - 如果在活跃事务列表 m_ids 中能找到 DB_TRX_ID，表明：① 在当前事务创建快照前，该记录行的值被事务 ID 为 DB_TRX_ID 的事务修改了，但没有提交；或者 ② 在当前事务创建快照后，该记录行的值被事务 ID 为 DB_TRX_ID 的事务修改了。这些情况下，这个记录行的值对当前事务都是不可见的。跳到步骤 5
  - 在活跃事务列表中找不到，则表明“id 为 trx_id 的事务”在修改“该记录行的值”后，在“当前事务”创建快照前就已经提交了，所以记录行对当前事务可见
5. 在该记录行的 DB_ROLL_PTR 指针所指向的 `undo log` 取出快照记录，用快照记录的 DB_TRX_ID 跳到步骤 1 重新开始判断，直到找到满足的快照版本或返回空

### 9.6 不可重复读问题：MVCC 解决



![image-20220825173946489](https://img.zxdmy.com/2022/202208251739695.png)







### 9.7 幻读问题：MVCC + Next-key-Lock 解决

`InnoDB`存储引擎在 RR 级别下通过 `MVCC`和 `Next-key Lock` 来解决幻读问题。

**1、执行普通 `select`，此时会以 `MVCC` 快照读的方式读取数据**：

在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 `Read View` ，并使用至事务提交。所以在生成 `Read View` 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”

**2、执行 `select...for update/lock in share mode、insert、update、delete` 等当前读**：

在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！`InnoDB` 使用 `Next-key Lock` 来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读。

## 10、分库与分表

### 10.1 分库与分表的概念

**分表**：

当单标的数据量达到千万级时，会极大影响 `SQL` 的执行性能。这时就需要分表。

分表就是把一个表的数据放到多个表中，然后通过一个表进行查询。

比如按照用户的ID来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。

**分库**：

在高并发的场景下，单库最多能提供2000左右的并发，如果超过这个值的话，数据库压力会很大。

在并发量高的情况下，需要将一个库拆分到多个库中，访问时只访问一个数据库。

这就是所谓的分库分表。

|              |          分库分表前          |              分库分表后              |
| :----------: | :--------------------------: | :----------------------------------: |
| 并发支撑情况 | MySQL 单机部署，扛不住高并发 |           能承受的并发增倍           |
| 磁盘使用情况 |  MySQL 单机磁盘容量几乎撑满  |    数据库服务器磁盘使用率大大降低    |
| SQL 执行性能 | 单表数据量太大，SQL 越跑越慢 | 单表数据量减少，SQL 执行效率明显提升 |

### 水平拆分与垂直拆分

**水平拆分**的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。

![img](https://img.zxdmy.com/2022/202208192050519.webp)

**垂直拆分**的意思，就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。

![img](https://img.zxdmy.com/2022/202208192050609.webp)

两种**分库分表的方式**：

- 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。
- 或者是按照某个字段hash一下均匀分散，这个较为常用。

range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。

hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表

## 12、主从同步与读写分类

### 简介

主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。

因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。

### 优点

1. 通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服务器上向外提供读功能，可以动态地调整从服务器的数量，从而调整整个数据库的性能。
2. 提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据
3. 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能
4. 数据备份。一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全

### 实现原理与主从复制流程

其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

基本原理流程，是3个线程以及之间的关联

主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；

从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中；

从：sql执行线程——执行relay log中的语句；

**复制过程如下**：

![img](https://img.zxdmy.com/2022/202208192051363.jpeg)

Binary log：主数据库的二进制日志

Relay log：从服务器的中继日志

第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。

第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。

第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。

### 主从同步延时问题

MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失问题；一个是并行复制，用来 解决主从同步延时问题。

- 半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。
- 并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

## 13、MySQL优化

### MySQL 的优化方法

### SQL 慢的原因有哪些，分别怎么优化？



### 8.1 MySQL 查询缓存（query_cache）

开启查询缓存后，在同样的查询条件以及数据情况下，会直接返回缓存中的结果。

**注意：**

+ 缓存能够**提升数据库的查询性能**；
+ 缓存也**带来额外的开销**，每次查询后都要做一次缓存操作，失效后还要销毁；
+ 查询缓存的**开启要谨慎**，尤其是写密集的应用。
+ 需要执行大量相同的 SQL 语句，且不需要频繁更改表时可开启。

查看 MySQL 是否已开启缓存：

```sql
SHOW VARIABLES LIKE 'have_query_cache';
```

![image-20220722163722539](https://img.zxdmy.com/2022/202207221637476.png)

更多操作：https://blog.csdn.net/weixin_56219549/article/details/123042365

具体可以在 `/usr/my.cnf` 中，添加设置并重启MySQL开启。



## 10、MySQL对于千万级的数据库或者大表怎么处理?

第一优化你的sql和索引；

第二加缓存，memcached,redis；

第三以上都做了后，还是慢，就做主从复制或主主复制，读写分离，可以在应用层做，效率高，也可以用三方工具

第四如果以上都做了还是慢，不要想着去做切分，mysql自带分区表，先试试这个

第五如果以上都做了，那就先做垂直拆分，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统

第六才是水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key,为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；





## mysql 页断裂了解吗

##　mysql 主从复制实现

## mysql 死锁检测（有点难了，只说了mysql有死锁检测和自动释放锁，但是实际的检测是怎么做的不会，答的话应该是：老版本深度优先遍历，新版本**稀疏等待关系图**）