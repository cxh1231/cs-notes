> https://javaguide.cn/database/mysql/mysql-questions-01.html
>
> [https://www.javalearn.cn/#/doc/MySQL/面试题](https://www.javalearn.cn/#/doc/MySQL/面试题)

## 1、数据库基础

### 1.1 数据库设计的基本步骤

1. **需求分析** : 分析用户的需求，包括数据、功能和性能需求。
2. **概念结构设计** : 主要采用 E-R 模型进行设计，包括画 E-R 图。
3. **逻辑结构设计** : 通过将 E-R 图转换成表，实现从 E-R 模型到关系模型的转换。
4. **物理结构设计** : 主要是为所设计的数据库选择合适的存储结构和存取路径。
5. **数据库实施** : 包括编程、测试和试运行
6. **数据库的运行和维护** : 系统的运行与数据库的日常维护。

### 1.2 数据库三范式概念

> **`范式`（ Normal Form）**，是英国人 E.F.Codd（关系数据库的老祖宗）在上个世纪70年代提出关系数据库模型后总结出来的，范式是关系数据库理论的基础，也是我们在设计数据库结构过程中所要遵循的规则和指导方法。目前有迹可寻的共有8种范式，依次是：1NF，2NF，3NF，BCNF，4NF，5NF，DKNF，6NF。

通常所用到的只是前三个范式，即：**第一范式（1NF），第二范式（2NF），第三范式（3NF）。**

+ **第一范式（1NF）**：要求属性不能被继续分割，是**数据库最基本的要求**。

  + 比如下面这个表不符合 1NF，将所有属性分解为最基本的属性即可。

    <img src="https://img.zxdmy.com/2022/202207221527511.png" alt="img" style="zoom:67%;" />

+ **第二范式（2NF）**：**消除非主属性对于码的部分函数依赖** ，即在满足 1NF 的前提下，要求表必须有主键，并且没有包含在主键中的列必须完全依赖于主键，不能只依赖于主键的一部分。

  + 比如下面这个表不符合 2NF，主码为【学号，课程号】，而关系模式中存在【姓名】等属性依赖于【学号】的关系，即【姓名】等属性对【学号，课程号】存在部分函数依赖。

    <img src="https://img.zxdmy.com/2022/202207221529500.png" alt="img" style="zoom: 80%;" />

  + 将其转化为如下 2 个表，即可符合 2NF：

    + 学生信息表【学号，姓名，性别，系名，公寓名称】
    + 成绩表【学号，课程号，成绩】

  + *但是，如果一个系一栋或几栋公寓的前提下，上面这种转化方式不符合 3NF。*

+ **第三范式（3NF）**： **消除非主属性对于码的函数依赖** ，即在满足 2NF 的前提下，要求非主键列必须直接依赖于主键，不能存在传递依赖，即不能存在【非主键列 A 依赖于非主键列 B ，非主键列 B 依赖于主键】的情况。

  + 比如一个 订单表【订单ID，订单日期，客户ID，客户名称，客户地址】，其主键是【订单ID】：
    + 订单表中非主键列，均完全依赖于主键【订单ID】，符合 2NF；
    + 但非主键列中存在一种直接依赖关系，即【客户名称，客户地址】直接依赖于【客户ID】；
    + 【客户名称，客户地址】是通过【客户ID】传递依赖于主键【订单ID】，故不符合 3NF。
  + 将其转化为如下 2 个表，即可符合 3NF：
    + 订单表【订单ID，订单日期，客户ID】
    + 客户表【客户ID，客户名称，客户地址】

## 2、MySQL 语句

### 2.1 删除语句 drop、delete、truncate 的区别

|          |       delete        |           truncate           |            drop            |
| :------: | :-----------------: | :--------------------------: | :------------------------: |
|   类型   | DML（数据操纵语言） |     DDL（数据定义语言）      |            DDL             |
|   回滚   |       可回滚        |           不可回滚           |          不可回滚          |
|   操纵   |      删除数据       |           清空数据           |          丢弃数据          |
| 删除内容 | 删除全部或部分数据  | 删除全部数据，自增主键初始化 | 删除整个表，以及索引和权限 |
| 删除速度 |    慢，逐行删除     |              快              |            最快            |

> delete 不加 where 子句，作用与 truncate 类似，但主键不初始化。

### 2.2 模糊查询 % 和 \* 通配符的区别

|          |      `*`       |     `%`      |     `_`     |
| :------: | :------------: | :----------: | :---------: |
|   作用   | 匹配所有结果集 | 替代多个字符 | 代替N个字符 |
|  优先级  |  高，优先执行  |      低      |     低      |
| 针对范围 |    所有字段    |   单个字段   |  单个字段   |

> 使用示例：
>
> `select * from user where name like '%三%' or id like '1_';`
>
> 则：`张三`、`张三丰` 等都可以被查询出来，`id` 是 `10`、`19` 的都可以被查询，而 `110` 等则不行。

### 2.3 varchar 和 char 的区别

|          |               char               |                         varchar                          |
| :------: | :------------------------------: | :------------------------------------------------------: |
|   长度   | **定长**，申请的长度即占用字符数 | **变长**，申请的长度是最大长度，实际占用`真实字符长度+1` |
|          |                                  |           最后一个字符存储的是实际占用空间长度           |
| 检索效率 |              效率高              |                                                          |

### 2.4 in 和 exists 的区别

|      |                   in                   |                     exists                     |
| :--: | :------------------------------------: | :--------------------------------------------: |
| 作用 |        把外表和内表作hash 连接         | 对外表作loop循环，每次loop循环再对内表进行查询 |
| 索引 | 内外表都进行全表扫描，**没有用到索引** |      not extsts 的子查询可以用到表的索引       |
| 效率 |                                        |                   一般比较高                   |

### 2.5 SQL 约束

- `NOT NULL`：用于控制字段的内容一定**不能为空**（NULL）。
- `UNIQUE`：控件**字段内容不能重复**，一个表**允许有多个 Unique 约束**。
- `PRIMARY KEY`：**主键**，也是用于控件**字段内容不能重复**，但它在一个表**只允许出现一个**。
- `FOREIGN KEY`：**外键**，用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。
- `CHECK`：用于**控制字段的值范围**。

## 3、存储过程

### 3.1 简介

> **`存储过程`（Stored Procedure）**是在大型数据库系统中，一组为了完成特定功能的SQL 语句集，它存储在数据库中，**一次编译后永久有效，比单纯的SQL速度更快**，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。
>
> **`存储过程`**中可以包含 **逻辑控制语句** 和 **数据操纵语句** , 它可以接受参数 , 输出参数 , 返回单个或多个结果集以及返回值。

### 3.2 存储过程的优缺点

**存储过程的优点**：

1. 存储过程 将复杂的 SQL 语句进行封装，在复杂查询过程中提供了一个替换位置；
2. 存储过程 在创建时即编译并存储在数据库中，其**运行速度比单纯的 SQL 语句更快**；
3. 存储过程 的调用只需要提供存储过程名和必要的参数信息，可以**减少网络流量，减轻网络负担**；
4. 存储过程 可以用于应用程序代码的不同位置，**代码精简一致**；
5. 存储过程 的访问权限（不基于表）可以向不同用户**分别授权**，**数据访问的安全性高**；
6. 存储过程 的参数数据类型，可以通过 SQLParameter 类指定，提高防御；
7. 提高代码安全，方式 SQL 注入。（但未彻底解决 , 例如将数据操作语言 `DML` 附加到输入参数）
8. 存储过程 的更新，比应用程序的更改、测试、部署需要的时间和精力更少，**可维护性高**【有争议】；

**存储过程的缺点**：

1.  难以调试和拓展，更没有拓展性
2.  存储过程 将应用程序绑定到 Server，所以使用存储过程封装业务逻辑将**限制应用程序的可移植性**。

> 《阿里巴巴Java开发手册》中规定，禁止使用存储过程。
>
> 可能原因是，项目的生命周期比较短，人员流动相比于传统的项目更加频繁，在这样的情况下，存储过程的管理确实是没有那么方便，同时，复用性也没有写在服务层那么好。

### 3.3 存储过程的基本使用

**简单存储过程实现：**

创建

```sql
create procedure GetUsers()
begin 
	select * from user; 
end;
```

调用

```sql
call GetUsers();
```

删除

```
drop procedure if exists GetUsers;
```

**带参数的存储过程实现：**

MySql 支持 IN (传递给存储过程) , OUT (从存储过程传出) 和 INOUT (对存储过程传入和传出) 类型的参数 , 存储过程的代码位于 BEGIN 和 END 语句内 , 它们是一系列 SQL 语句 , 用来检索值 , 然后保存到相应的变量 (通过指定INTO关键字) ;

创建

```sql
create procedure GetNameByID(
	in userID int,
	out userName varchar(200)
)
begin
	select name from user
	where id = userID
	into userName;
end;
```

调用

```
call GetNameByID(1, @userName);
select @userName;
```

## 4、数据库引擎

### 4.1  InnoDB 与 MyISAM 的区别

> 在大多数的情况下，**直接选择使用 InnoDB 引擎都是最合适的**，InnoDB 也是 MySQL 的默认存储引擎。

|          |                            InnoDB                            |                            MyISAM                            |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|   事务   |                             支持                             |                            不支持                            |
|   外键   |                             支持                             |                            不支持                            |
| 索引结构 |                            B+ 树                             |                            B+ 树                             |
| 索引数据 | **聚集索引**，数据文件和（主键）索引**绑定**，必须有主键索引，**叶子节点即为数据文件**，主键索引效率很高 | **非聚集索引**，数据文件与索引**分离**，索引保存指向数据文件的**指针** |
| 主键索引 |                            必须有                            |                             可无                             |
| 辅助索引 |      辅助索引需要两次查询，先查主键，再通过主键查询数据      |                  主键索引与辅助索引互相独立                  |
| 全文索引 |                            不支持                            |                 支持，查询效率上 MyISAM 要高                 |
|    锁    |                    支持表、行（默认）级锁                    |                          支持表级锁                          |
|  表行数  |                       不保存，全表扫描                       |                       通过一个变量保存                       |
|   压缩   |                                                              |                    表格可被压缩后进行查询                    |
| 存储文件 |                frm：表定义文件，ibd：数据文件                |        frm：表定义文件，myd：数据文件，myi：索引文件         |
| 应用场景 |            适合频繁修改以及涉及到安全性较高的应用            |                  适合查询以及插入为主的应用                  |

> 为什么 `InnoDB` 没有**行数**这个变量？
>
> 因为 InnoDB 的**事务特性**，在**同一时刻表中的行数对于不同的事务而言是不一样的**，因此count统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。

### 4.2 InnoDB 事务的 ACID 特性保证方式

+ **原子性**：使用 `undo log`（**回滚日志**）来保证；
+ **持久性**：使用 `redo log` （**重做日志**）来保证；
+ **隔离性**：通过 **锁机制**、**MVCC** 等手段来保证（ 默认支持的隔离级别是  `REPEATABLE-READ` ）；
+ **一致性**：保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。

### 4.3 锁机制与 InnoDB 锁算法

**表级锁和行级锁对比：**

- **表级锁：** MySQL 中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。
- **行级锁：** MySQL 中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

**InnoDB 存储引擎的锁的算法有三种：**

- `Record lock`：记录锁，单个行记录上的锁
- `Gap lock`：间隙锁，锁定一个范围，不包括记录本身
- `Next-key lock`：record+gap 临键锁，锁定一个范围，包含记录本身

## 5、MySQL 执行过程

1. **建立连接与权限校验**：**客户端**通过 `TCP` 连接发送连接请求到 `MySQL` **连接器**，**连接器**会对该请求进行**权限验证及连接资源分配**；
2. **查询缓存**：判断缓存是否在哈希表中。在查询命中时，`MySQL` 不会进行解析查询语句，而是**直接使用** SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。
3. **解析与预处理**：即**解析器**通过**词法分析**和**语法分析**验证`SQL`的合法性，并生成**解析树**；**预处理器**则根据 MySQL 规则进一步检查解析树的合法性，以及检查数据表和数据列是否存在，解析别名看是否存在歧义。
4. **优化**：**优化器**负责将语法树转化成执行计划，比如根据 SQL 语句，决定使用哪个索引，或者决定表的连接顺序等。
5. **执行**：**执行器**负责根据执行计划，调用**存储引擎**的API接口来完成整个查询工作。
6. **返回结果**：将执行的结果返回给客户端。如果开启了查询缓存，同时会将数据缓存到查询缓存中。

![image-20220819200441740](https://img.zxdmy.com/2022/202208192004163.png)

更新语句执行会复杂一点。需要检查表是否有排它锁，写 binlog，刷盘，是否执行 commit。

## 6、MySQL 的锁

### 6.1 锁的简介

当多个用户**并发**地存取数据时，在数据库中就会产生**多个事务同时存取同一数据**的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，**破坏数据库的一致性**。

MySQL 锁的作用：**在多用户环境下保证数据库完整性和一致性**。

MySQL 锁的作用范围：**行** 或 **表**。

### 6.2 锁的宏观分类

|    场景    |                     锁分类                     |
| :--------: | :--------------------------------------------: |
|   粒度上   |             行级锁、表级锁、页级锁             |
|   类别上   |         共享锁（读锁）、排他锁（写锁）         |
| 并发控制上 | 乐观锁（乐观并发控制）、悲观锁（悲观并发控制） |

#### 锁粒度：行级锁与表级锁

关系型数据库中，可以 **按照锁的粒度** 把数据库锁分为**行级锁**、**表级锁** 和 **页级锁**。

|          |       行级锁       |            表级锁            |         页级锁         |
| :------: | :----------------: | :--------------------------: | :--------------------: |
|   简介   | 只对当前操作行加锁 |     对当前操作的整表加锁     | 介于行级锁和表级锁中间 |
| 应用引擎 |       InnoDB       |        InnoDB、MyISAM        |          BDB           |
|   粒度   |        最小        |             最大             |           中           |
|   开销   |         大         |              小              |           中           |
| 加锁速度 |         慢         |              快              |           中           |
|  并发度  |  高，锁冲突概率低  |       低，锁冲突概率高       |   一般，冲突概率中等   |
|   死锁   |       会死锁       |           不会死锁           |         会死锁         |
|   细分   |   共享锁、排他锁   | 共享读锁、独占写锁（排他锁） |           —            |

#### 锁类别：共享锁与排他锁

从 **锁的类别** 上来讲，有 **共享锁** 和 **排他锁**：

|          |    共享锁（Shared Locks，S锁，读锁）    |    排他锁（Exclusive Locks，X锁，写锁、独占锁）     |
| :------: | :-------------------------------------: | :-------------------------------------------------: |
|   简介   |      加共享锁后，只能读，不能改删       |     加排他锁后，可以增、改、删，不允许加任何锁      |
| 应用场景 | 进行数据**读取**时，对数据加 **共享锁** |       进行数据**写入**时，对数据加 **排他锁**       |
| 加锁限制 |        可以同时加**多个 共享锁**        | 只能加**一个 排他锁**，与其他的 排他锁、共享锁 相斥 |

用上面的例子来说就是用户的行为有两种：

+ 一种是来看房，多个用户一起看房是可以接受的。
+ 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。

#### 并发控制：乐观锁与悲观锁

**数据库管理系统**（DBMS）中的 **并发控制** 的任务是确保在多个事务同时存取数据库中同一数据时，不破坏**事务**的**隔离性**和**统一性**，以及**数据库**的**统一性**。

**乐观锁**（乐观并发控制）和**悲观锁**（悲观并发控制）是**并发控制主要采用的技术手段**。

|          |                            乐观锁                            |                            悲观锁                            |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|   简介   | 假设不会发生并发冲突，只在提交操作时检查是否违法数据库的完整性 |    假设一定发生并发冲突，屏蔽一切可能违反数据完整性的操作    |
| 实现方法 |  在修改数据的时候把事务锁起来，通过version的方式来进行锁定   |        在查询完数据的时候就把事务锁起来，直到提交事务        |
| 实现方式 |                    版本号机制 或 CAS算法                     |                        数据库的锁机制                        |
| 应用场景 | **多读场景**：很少发生冲突，使用 **乐观锁** 省去锁的开销，加大系统吞吐量 | **多写场景**：经常发生冲突，导致上层应用不断重试，降低了性能，适合悲观锁 |

### 6.3 锁的微观分类

|           锁名            | 范围 |                             简介                             |
| :-----------------------: | :--: | :----------------------------------------------------------: |
| 意向锁（Intention Locks） | 表锁 |    表明“某个事务正在某些行持有了锁、或该事务准备去持有锁”    |
|  记录锁（Record Locks）   | 行锁 |                      锁住索引记录的一行                      |
|    间隙锁（Gap Locks）    | 行锁 |    锁住一个索引区间（开区间），保证索引区间不会被插入数据    |
| 临键锁（Next-Key Locks）  | 行锁 | Record Lock + Gap Lock，左开右闭区间，唯一属性退化为 Record Lock |
| 自增锁（AUTO-INC Locks）  | 表锁 | 特殊的表级锁，发生涉及AUTO_INCREMENT列的事务性插入操作时产生 |

对于如下的SQL语句：

```sql
update user set name=“hello” where name=“world” and sex="M";
update user set name=“hello” where name=“world”;
```

+ 如果更新条件**没有走索引**，则进行全表扫描，阻止其他任何更新操作，上升为`表锁`；
+ 如果更新条件为**索引字段**，但**并非唯一索引**（含主键索引），则要保证符合条件的记录加上排他锁，并锁定非唯一索引对应的主键索引的值，同时保证锁定区间不能插入新的数据，索引会使用 `临键锁`；
+ 如果更新条件为**索引字段**，并且是**唯一索引**，则降级为 `记录锁`。

### 6.4 死锁与解决方案

数据库的死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

**常见的死锁解决方法**：

+ 对于不同程序并发存取多个表的情况，约定**以相同的顺序访问表**，可以大大降低死锁机会；
+ 在同一个事务中，尽可能做到**一次锁定所需要的所有资源**，减少死锁产生概率；
+ 对于容易产生死锁的业务部分，可以尝试升级锁定颗粒度，通过**表级锁**来减少死锁产生的概率；
+ 如果业务处理不好，可以用 **分布式事务锁** 或者使用**乐观锁**。

### 6.5 锁的优化

- **隔离级别**：尽量使用**较低**的隔离级别；
- **设计索引**：尽量**使用索引去访问数据**，加锁更加精确，从而减少锁冲突；
- **事务大小**：选择合理的事务大小，给记录显示加锁时，最好**一次性请求足够级别的锁**。如修改数据的事务，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁；
- **访问顺序**：不同的程序访问一组表的时候，应尽量**约定一个相同的顺序访问各表**，对于一个表而言，尽可能的**固定顺序的获取表中的行**。这样大大的减少死锁的机会；
- **查询条件**：尽量**使用相等条件访问数据**，这样可以避免间隙锁对并发插入的影响；
- **申请锁**：不要申请超过实际需要的锁级别；
- **使用锁**：数据查询时，非不要不加锁。MySQL 的 MVCC可以实现事务中的查询不用加锁；
- 优化事务性能：MVCC 只在 committed read（读提交）和 repeatable read （可重复读）两种隔离级别下工作；
- 对于特定的事务，可以使用表级锁来提高处理速度，或者减少死锁的可能。

## 7、MySQL 事务

### 7.1 事务简介

**事务是一个不可分割的数据库操作序列**，也**是数据库并发控制的基本单位**，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的**一组操作**，要么都执行，要么都不执行。

转账是事务的典型例子：

假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。

### 7.2 事务的 ACID 特性

> **是逻辑上的一组操作，要么都执行，要么都不执行。**

1. **原子性**（`Atomicity`） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. **一致性**（`Consistency`）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
3. **隔离性**（`Isolation`）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
4. **持久性**（`Durability`）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

### 6.2 并发事务的问题

- **脏读**（Dirty read）：即 `事务A` 正在**访问并修改数据**，在**修改提交至数据库之前**，`事务B` 访问了 `事务A` 修改后的数据。因为 `事务A` 修改的**数据未提交**，`事务B` 读取的数据就是 `脏数据`。如果 `事务A` 发生 **回滚** 操作，则 `事务B` 依据此 `脏数据` 所做的操作是错误的。
- **丢失修改**（Lost to modify）：即 `事务A` 读取了一个数据，`事务B` 也读取了此数据，然后 `事务A` 修改了此数据，之后 `事务B` 也对此数据进行修改，这就导致 `事务A` 的修改结果丢失。
- **不可重复读**（Unrepeatable read）：即 `事务A` 执行过程中，会有多次访问某个数据的过程。在 `事务A` 两次访问某个数据之间，`事务B` 对此数据进行修改，导致 `事务A` 两次读取前后的数据不一致。
- **幻读**（Phantom read）：幻读与不可重复读类似。即 `事务A` 先读取了几行数据，接着 `并发事务B` 插入了一些数据，然后 `事务A` 又进行了查询，会查询到一些原本不存在的记录，就像发生了幻觉一样，故成为幻读。

> 总结：
>
> 脏读是一个事物回滚影响另一个事务；
>
> 不可重复读侧重于修改；
>
> 幻读侧重于新增或删除。

### 6.3 事务的隔离级别与锁关系

#### 隔离级别

> 如何实现事务的隔离？
>
> https://haicoder.net/note/MySQL-interview/MySQL-interview-MySQL-trans-level.html

|      隔离级别（从低到高）      |                简介                | 脏读 | 不可重复读 | 幻读 |
| :----------------------------: | :--------------------------------: | :--: | :--------: | :--: |
| Read Uncommitted（读取未提交） |     允许读取尚未提交的更新数据     |  √   |     √      |  √   |
|  Read Committed（读取已提交）  |   允许读取并发事务已经提交的数据   |  ×   |     √      |  √   |
|  Repeatable Read（可重复读）   | 对同一字段的多次读取结果都是一致的 |  ×   |     ×      |  √   |
|    Serializable（可串行化）    |       所有的事务依次逐个执行       |  ×   |     ×      |  ×   |

详述：

+ `Read Uncommitted`（读取未提交内容）：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。`读未提交` 隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。**读取未提交的数据，也被称之为脏读**（Dirty Read）。

- `Read Committed`（读取提交内容）：这是大多数数据库系统的默认隔离级别（如 Oracle ，但不是 MySQL）。它满足了隔离的简单定义：**一个事务只能看见已经提交事务所做的改变**。**读取已提交的内容，会发生不可重复读**（Nonrepeatable Read）问题，因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一 select 可能返回不同结果。

- `Repeatable Read`（可重复读）：这**是 MySQL 的默认事务隔离级别**，它确保**同一事务的多个实例在并发读取数据时，会看到同样的数据行**。不过理论上，这会导致另一个棘手的问题：**幻读** （Phantom Read）。

- `Serializable`（可串行化）：**通过强制事务排序，使之不可能相互冲突，从而解决幻读问题**。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

总结：

+ **事务隔离机制的实现基于锁机制和并发调度**。其中**并发调度**使用的是`MVVC`（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。
+ **隔离级别越低，事务请求的锁越少**。但 `MySQL` 的`InnoDB` 引擎默认的是 `可重复的` 隔离级别，相比较于 `读已提交` 隔离级别，并不会有任何性能的损失。
+ InnoDB 存储引擎在 `分布式事务` 的情况下一般会用到 **SERIALIZABLE(可串行化)** 隔离级别。

#### 隔离级别与锁关系

|     隔离级别     |                         锁关系                         |
| :--------------: | :----------------------------------------------------: |
| Read Uncommitted |   读取数据不加共享锁，因此与排他锁不冲突（导致脏读）   |
|  Read Committed  |       读取数据加共享锁，语句执行完成后释放共享锁       |
| Repeatable Read  | 读取操作加共享锁，事务提交前不释放，事务执行完毕后释放 |
|   Serializable   |      锁定整个范围的键，并一直持有锁，直至事务完成      |

### 6.4 事务日志与二进制日志

**InnoDB 数据库引擎** 的**事务日志**包含两种：`redo log` 和 `undo log`；还有一种是不属于事务日志的**二进制日志** `bin log`。

+ `undo log` ，指事务开始之前，操作任何数据之前，先将需操作前一个版本的数据备份到一个地方；
+ `redo log` ，指事务中操作的任何数据，将最新的数据备份到一个地方；
+ `bin log` ，记录数据库执行的写入性操作（不包括查询）信息，以二进制的形式保存在磁盘中。

> - 逻辑日志：可以简单理解为记录的就是 SQL 语句；
> - 物理日志：`mysql` 数据最终是保存在数据页中的，物理日志记录的就是数据页变更。

宏观比较：

|             |         undo log         |      redo log       |          bin log           |
| :---------: | :----------------------: | :-----------------: | :------------------------: |
|    定位     |         回滚日志         |      重做日志       |          归档日志          |
|    用途     | 保存事务上一个版本、MVCC | 提升更新性能（WAL） |         数据库重建         |
|  故障恢复   |    保证主库数据原子性    |  保证主库数据一致   |      保证从库数据一致      |
|  所在位置   |       InnoDB 引擎        |     InnoDB 引擎     |        MySQL Server        |
| 写 log 时机 |        事务开始前        |       事务中        |         提交事务时         |
|  log 内容   |         逻辑日志         |     物理页修改      |        原始修改逻辑        |
|  log 空间   |            —             |     持续追加写      |           循环写           |
|   可关闭    |           不可           |        不可         | 单机、无数据重建需求可关闭 |

+ 事务日志的目的：实例或者介质失败，事务日志文件保证提交的记录不丢失，并能继续处理，即 **保证即使数据库发生异常重启，之前提交的记录都不会丢失**。
+ 二进制日志的目的：作主从复制，时间点恢复使用。

#### undo log

`MySQL` 事务的 `原子性` ，底层就是通过 `undo log` 实现的。

`undo log` 主要记录了数据的逻辑变化，其实际是对应 增删改 操作的反操作，比如一条 `INSERT` 语句，对应一条`DELETE` 的 `undo log` ，对于每个 `UPDATE` 语句，对应一条相反的 `UPDATE` 的 `undo log` ，这样在发生错误时，就能回滚到事务之前的数据状态。同时， `undo log` 也是 `MVCC`(多版本并发控制)实现的关键。

**主要作用**

1. 保存了事务发生之前的数据的一个版本，可以用于回滚；
2. 同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读。

**生命周期**

1. **事务开始之前**，将当前事务版本生成 undo log，undo log 也会产生 redo log 来保证 undo log 的可靠性。
2. 当**事务提交之后**，undo log 并不能立马被删除，而是**放入待清理的链表。**
3. 由 **purge 线程**判断是否有其它事务在使用 undo 段中表的上一个事务之前的版本信息，从而决定是否可以清理 undo log 的日志空间。

![image-20220819203837173](https://img.zxdmy.com/2022/202208192038621.png)

**存储内容**

undo log 存储的是逻辑格式的日志，保存了事务发生之前的上一个版本的数据，可以用于回滚。当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着 undo 链找到满足其可见性的记录。

**存储位置**

默认情况下，undo 文件是保存在共享表空间的，也即 ibdatafile 文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的 undo log 信息，这些信息全部保存在共享表空间中，因此共享表空间可能会变得很大，默认情况下，也就是 undo log 使用共享表空间的时候，被“撑大”的共享表空间是不会、也不能自动收缩的。因此，MySQL5.7 之后的“独立 undo 表空间”的配置就显得很有必要了。

#### redo log

`redo log` 是物理日志，记录了每次操作在页上做了什么修改。

写 `redo log` 也是需要写磁盘的，但它的好处就是顺序IO，写入的速度很快（比随机IO快很多）。

在 **事务的执行过程中**，便开始写 `redo log`。

**原因**：

+ 传统的在事务提交过程中，将设计修改的数据全部刷新至磁盘的操作方式，存在性能问题；
+  `Innodb` 以 `页` 为单位进行磁盘交互，而一个事务很可能只修改一个数据页里面的几个字节，这种情况，将完整的数据页刷到磁盘的话，浪费资源；
+ 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差

为了保证事务的一致性，以及数据的持久化，因此 `MySQL` 设计了 `redo log` ，只记录事务对数据页做了哪些修改，即可解决性能问题。

> 在 `InnoDB` 中，既有`redo log` 需要刷盘，还有 `数据页` 也需要刷盘， `redo log` 存在的意义主要就是降低对 `数据页` 刷盘的要求。

**日志记录形式**：

`redo log` 采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。

<img src="https://img.zxdmy.com/2022/202208222128015.png" alt="image-20220822205124008" style="zoom:50%;" />

在上图中， `write pos` 表示 `redo log` 当前记录的 `LSN` (逻辑序列号)位置， `check point` 表示 数据页更改记录 刷盘后对应 `redo log` 所处的 `LSN`(逻辑序列号)位置。

`write pos` 到 `check point` 之间的部分是 `redo log` 空着的部分，用于记录新的记录；

`check point` 到 `write pos` 之间是 `redo log` 待落盘的数据页更改记录。

当 `write pos`追上`check point` 时，会先推动 `check point` 向前移动，空出位置再记录新的日志。

启动 `innodb` 的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。

因为 `redo log`记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如 `binlog` )要快很多。

重启`innodb` 时，首先会检查磁盘中数据页的 `LSN` ，如果数据页的`LSN` 小于日志中的 `LSN` ，则会从 `checkpoint` 开始恢复。

还有一种情况，在宕机前正处于`checkpoint` 的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 `LSN` 大于日志中的 `LSN`，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。

**基本流程**：

`redo log` 包括两部分：

+ 内存中的日志缓冲( `redo log buffer` )，
+ 磁盘上的日志文件( `redo log file`)。

`mysql` 每执行一条 `DML` 语句，先将记录写入 `redo log buffer`，后续某个时间点再一次性将多个操作记录写到 `redo log file`。

这种 **先写日志，再写磁盘** 的技术就是 `MySQL`里经常说到的 `WAL(Write-Ahead Logging)` 技术。

在计算机操作系统中，用户空间( `user space` )下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间( `kernel space` )缓冲区( `OS Buffer` )。

因此， `redo log buffer` 写入 `redo logfile` 实际上是先写入 `OS Buffer` ，然后再通过系统调用 `fsync()` 将其刷到 `redo log file`中。

![image-20220822205508770](https://img.zxdmy.com/2022/202208222055119.png)

**具体的落盘策略可以进行配置** 。

`mysql` 支持三种将 `redo log buffer` 写入 `redo log file` 的时机，可以通过 `innodb_flush_log_at_trx_commit` 参数配置，各参数值含义如下：

![image-20220822205801981](https://img.zxdmy.com/2022/202208222058379.png)

- 0：延迟写。不会在事务提交时立即将redo log buffer写入到os buffer，而是每秒写入os buffer，然后立即写入到redo log file，也就是每秒刷盘；
- 1：实时写，实时刷。每次事务提交都会将redo log buffer写入os buffer，然后立即写入redo log file。数据能够及时入盘，但是每次事务提交都会刷盘，效率较低；
- 2：实时写，延时刷。每次事务提交都将redo log buffer写入os buffer，然后每秒将os buffer写入redo log file。

#### bin log

`bin log` 用于记录数据库执行的表结构变更（例如 CREATE、ALTER TABLE）以及表数据修改（INSERT、UPDATE、DELETE）等的写入性操作（不包括查询，如 SELECT 和 SHOW 等）信息，以二进制的形式保存在磁盘中，通过追加的方式进行写入。

`bin log` 是 `MySQL`的逻辑日志，并且由 `Server` 层进行记录，使用任何存储引擎的 `MySQL` 数据库都会记录 `bin log` 日志。可以简单的理解为它存储着每条变更的SQL语句。

MySQL `bin log` 以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的二进制日志是事务安全型的。`bin log` 的主要目的是复制和恢复。

**刷盘时机**：

`mysql` 通过 `sync_binlog` 参数控制 `biglog` 的刷盘时机，取值范围是 `0-N`：

- 0：不去强制要求，由系统自行判断何时写入磁盘；
- 1：每次 `commit` 的时候都要将 `binlog` 写入磁盘（默认）；
- N：每N个事务，才会将 `binlog` 写入磁盘。

**三种模式**

binlog 有三种格式，各有优缺点：

- **statement：** 基于 SQL 语句的模式，某些语句和函数如 UUID, LOAD DATA INFILE 等在复制过程可能导致数据不一致甚至出错。
- **row：** 基于行的模式，记录的是行的变化，很安全。但是 binlog 会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大。
- **mixed：** 混合模式，根据语句来选用是 statement 还是 row 模式。

### 6.5 事务的实现原理

事务是基于 **重做日志文件**(redo log)和 **回滚日志**(undo log)实现的。

+ 每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。

+ 每当有修改事务时，还会产生 `undo log`，如果需要回滚，则根据 undo log 的反向语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。undo log 主要实现数据库的一致性。

## 9、MySQL 索引

### 9.1 索引简介

索引是一种数据结构，是一种文件。

数据库索引，是数据库管理系统中一个排序的数据结构，是一种特殊的文件（InnoDB数据表上的索引是表空间的一个组成部分），它们包含着对数据表里所有记录的引用指针，以协助快速查询、更新数据库表中数据，并占用一定的物理存储空间。

更通俗的说，索引就相当于目录，为了方便查找书中的内容，通过对内容建立索引形成目录。而

### 9.2 索引的优缺点

**优点** ：

- 使用索引可以大大 **加快数据的检索速度**（大大减少检索的数据量）, 这也是创建索引的 **主要原因**；
- 使用索引可以在查询过程中，**使用优化隐藏器**，提供系统性能；
- 通过创建**唯一性索引**，可以保证数据库表中每一行数据的**唯一性**。

**缺点** ：

- **时间方面：创建索引和维护索引需要耗时**。即：当对表中的数据进行增、删、改时，索引需要动态维护，会降低 SQL 的执行效率；
- **空间方面：索引需要占用物理文件存储**，也会耗费一定空间。

### 9.3 索引的底层数据结构

#### Hash 索引

基于哈希表实现，只有精确匹配索引所有列的查询才有效。

对于每一行数据，存储引擎都会对所有的索引列计算一个**哈希码**（hash code），并且Hash索引将所有的**哈希码**存储在索引中，同时在索引表中保存指向每个数据行的指针。

![image-20220819201418648](https://img.zxdmy.com/2022/202208192014972.png)

> **为什么MySQL 没有使用 Hash 作为索引的数据结构？**
>
> + **Hash 冲突问题**：哈希表存在哈希冲突问题；
> + 最大缺点：**Hash 索引不支持顺序和范围查询**，使得对表数据进行排序或范围查询时，索引不可用。

#### B 树索引

`B-Tree` 能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，**数据分布在各个节点之中**。

![image-20220819201836182](https://img.zxdmy.com/2022/202208192018448.png)

但 MySQL 并没有采用这种索引结构。

#### B\+ 树索引（实际应用）

**B\+ 树的数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址**。

![image-20220819201946478](https://img.zxdmy.com/2022/202208192019737.png)

相对于 `B-Tree` ，`B+Tree` 进行范围查找时，只需要查找两个节点，进行遍历即可。而 `B-Tree` 需要获取所有节点，相比之下 `B+Tree` 效率更高。

`B-Tree` 的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 `B+Tree` 的检索效率就很稳定了，**任何查找都是从根节点到叶子节点的过程**，叶子节点的顺序检索很明显。

**B+ 树的性质**：

- n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
- 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
- B+ 树中，数据对象的插入和删除仅在叶节点上进行。
- B+ 树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。

#### 为什么索引结构默认使用B+Tree

**相比较于B-tree，B+Tree的优点**：

- **B+树的磁盘读写代价更低**：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B(B-)树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对`IO读写次数就降低`了。
- 由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在`区间查询`的情况，所以通常B+树用于数据库索引。

**Hash的不足**：

- 虽然可以快速定位，但是没有顺序，IO复杂度高；

- 基于Hash表实现，只有Memory存储引擎显式支持哈希索引 ；
- 适合**等值查询**，如=、in()、<=>，不支持范围查询 ；
- 因为不是按照索引值顺序存储的，就不能像B+Tree索引一样利用索引完成[排序](https://www.javalearn.cn/#/) ；
- Hash索引在查询等值时非常快 ；
- 因为Hash索引始终索引的**所有列的全部内容**，所以不支持部分索引列的匹配查找 ；
- 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 。

**二叉树的不足**： 树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。

**红黑树的不足**： 树的高度随着数据量增加而增加，IO代价高。

### 9.4 索引的分类

#### 存储结构上：

BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式。

#### 应用层次上：

|       索引名称       |                           简介                           |      |
| :------------------: | :------------------------------------------------------: | ---- |
|       普通索引       |      一个索引只包含单个列，一个表可以有多个单列索引      |      |
|       唯一索引       |             索引列的值必须唯一，但允许有空值             |      |
| 联合索引（复合索引） | 多列值组成一个索引，专门用于组合搜索，其效率大于索引合并 |      |



MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。

具体原因为:

MySQL使用索引时需要索引有序，假设现在建立了"name，age，school"的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。

当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。

**最左前缀原则**就是**最左优先**，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。 mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

#### 数据的物理顺序与键值的逻辑（索引）顺序关系上：

- 聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。
- 非聚簇索引： 不是聚簇索引，就是非聚簇索引

在 InnoDB 里，索引B+ Tree的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引，即将数据存储与索引放到了一块，找到索引也就找到了数据。

而索引B+ Tree的叶子节点存储了主键的值的是非主键索引，也被称之为非聚簇索引、二级索引。

**聚簇索引与非聚簇索引的区别**：

- 非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键（行号）
- 对于InnoDB来说，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为**回表**。第一次索引一般是顺序IO，回表的操作属于随机IO。需要回表的次数越多，即随机IO次数越多，我们就越倾向于使用全表扫描 。
- 通常情况下， 主键索引（聚簇索引）查询只会查一次，而非主键索引（非聚簇索引）需要回表查询多次。当然，如果是覆盖索引的话，查一次即可
- 注意：MyISAM无论主键索引还是二级索引都是非聚簇索引，而InnoDB的主键索引是聚簇索引，二级索引是非聚簇索引。我们自己建的索引基本都是非聚簇索引。

**非聚簇索不一定会回表查询**，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。一个索引包含（覆盖）所有需要查询字段的值，被称之为"覆盖索引"。

举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行`select score from student where score > 90`的查询时，在索引的叶子节点上，已经包含了score 信息，不会再次进行回表查询。

### 索引创建

创建索引有三种方式。

1、 在执行CREATE TABLE时创建索引

```sql
CREATE TABLE user_index2 (
                           id INT auto_increment PRIMARY KEY,
                           first_name VARCHAR (16),
                           last_name VARCHAR (16),
                           id_card VARCHAR (18),
                           information text,
                           KEY name (first_name, last_name),
                           FULLTEXT KEY (information),
                           UNIQUE KEY (id_card)
);
```

2、 使用ALTER TABLE命令去增加索引。

```sql
ALTER TABLE table_name ADD INDEX index_name (column_list);
```

ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。

其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。

索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。 3、 使用CREATE INDEX命令创建。

```sql
CREATE INDEX index_name ON table_name (column_list);
```

### 前缀索引

因为可能我们索引的字段非常长，这既占内存空间，也不利于维护。所以我们就想，如果只把很长字段的前面的公共部分作为一个索引，就会产生超级加倍的效果。但是，我们需要注意，order by不支持前缀索引 。

流程是：

先计算完整列的选择性 :` select count(distinct col_1)/count(1) from table_1 `

再计算不同前缀长度的选择性 :`select count(distinct left(col_1,4))/count(1) from table_1 `

找到最优长度之后，创建前缀索引 :` create index idx_front on table_1 (col_1(4))`

### 索引下推

MySQL 5.6引入了索引下推优化。默认开启，使用SET optimizer_switch = ‘index_condition_pushdown=off’;可以将其关闭。

- 有了索引下推优化，可以在**减少回表次数**
- 在InnoDB中只针对二级索引有效

官方文档中给的例子和解释如下：

在 people_table中有一个二级索引(zipcode，lastname，address)，查询是SELECT * FROM people WHERE zipcode=’95054′ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’;

- 如果没有使用索引下推技术，则MySQL会通过zipcode=’95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断数据是否符合条件
- 如果使用了索引下推技术，则MYSQL首先会返回符合zipcode=’95054’的索引，然后根据lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。

### 索引失效

##### 1、使用!= 或者 <> 导致索引失效

##### 2、类型不一致导致的索引失效

##### 3、函数导致的索引失效

如：

```
SELECT * FROM `user` WHERE DATE(create_time) = '2020-09-03';
```

如果使用函数在索引列，这是不走索引的。

##### 4、运算符导致的索引失效

```
SELECT * FROM `user` WHERE age - 1 = 20;
```

如果你对列进行了（+，-，*，/，!）, 那么都将不会走索引。

##### 5、OR引起的索引失效

```
SELECT * FROM `user` WHERE `name` = '张三' OR height = '175';
```

OR导致索引是在特定情况下的，并不是所有的OR都是使索引失效，如果OR连接的是同一个字段，那么索引不会失效，反之索引失效。

##### 6、模糊搜索导致的索引失效

```
SELECT * FROM `user` WHERE `name` LIKE '%冰';
```

当`%`放在匹配字段前是不走索引的，放在后面才会走索引。

##### 7、NOT IN、NOT EXISTS导致索引失效

### 创建索引的注意事项

**创建原则**

1、最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

2、=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

3、尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。

4、索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。

5、尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

**注意事项**

- 选择合适的字段
  - 不为NULL的字段 , 如果需要 , 使用0 , 1 , true , false来代替
  - 被频繁查询的字段
  - 被作为条件查询的字段
  - 频繁需要排序的字段
  - 频繁连接的字段
- 被频繁更新的字段应谨慎建立索引
- 尽量考虑联合索引而非单列索引
- 尽量避免冗余索引
  - 能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引



- 非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；
- 取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；
- 索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。

### mysql 联合索引创建优化？

### MySQL 主键索引和唯一索引的区别

### mysql 索引使用



## 10、MySQL 的 MVCC（多版本并发控制）

MVCC， 即多版本并发控制。

MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。

根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。

#### 解决什么问题?

- 大多数的MYSQL事务型存储引擎,如InnoDB都不使用一种简单的行锁机制.事实上,他们都和MVCC–多版本并发控制来一起使用
- 锁机制可以控制并发操作,但是其系统开销较大,而MVCC可以在大多数情况下代替行级锁,使用MVCC,能降低其系统开销

#### 实现

通过保存数据在某个时间点的快照来实现的. 不同存储引擎的MVCC. 不同存储引擎的MVCC实现是不同的,典型的有乐观并发控制和悲观并发控制

**快照读**

如果读取的行正在执行 `DELETE` 或 `UPDATE` 操作，这时读取操作不会去等待行上锁的释放。相反地，`InnoDB` 存储引擎会去读取行的一个快照数据，对于这种读取历史数据的方式，我们叫它快照读

**锁定读**

如果执行的是下列语句，就是锁定读

- `select ... lock in share mode`

- `select ... for update`

- `insert`、`update`、`delete` 操作

  在锁定读下，读取的是数据的最新版本

### InnoDB 对 MVCC 的实现

`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改

### MVCC 的实现原理

对于 InnoDB ，聚簇索引记录中包含 3 个隐藏的列：

- ROW ID：隐藏的自增 ID，如果表没有主键，InnoDB 会自动按 ROW ID 产生一个聚集索引树。
- 事务 ID：记录最后一次修改该记录的事务 ID。
- 回滚指针：指向这条记录的上一个版本。

我们拿上面的例子，对应解释下 MVCC 的实现原理，如下图：

![image-20220819204225061](https://img.zxdmy.com/2022/202208192042463.png)

如图，首先 insert 语句向表 t1 中插入了一条数据，a 字段为 1，b 字段为 1， ROW ID 也为 1 ，事务 ID 假设为 1，回滚指针假设为 null。当执行 update t1 set b=666 where a=1 时，大致步骤如下：

- 数据库会先对满足 a=1 的行加排他锁；
- 然后将原记录复制到 undo 表空间中；
- 修改 b 字段的值为 666，修改事务 ID 为 2；
- 并通过隐藏的回滚指针指向 undo log 中的历史记录；
- 事务提交，释放前面对满足 a=1 的行所加的排他锁。

在前面实验的第 6 步中，session2 查询的结果是 session1 修改之前的记录，这个记录就是**来自 undolog** 中。

因此可以总结出 MVCC 实现的原理大致是：

InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本，这个历史版本存放在 undo log 中。如果要执行更新操作，会将原记录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事务此时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。

MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。

## 11、分库分表

### 简介

**分表**

比如你单表都几千万数据了，你确定你能扛住么？绝对不行，单表数据量太大，会极大影响你的 sql执行的性能，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。

分表就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。

**分库**

分库就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。

这就是所谓的分库分表。

![image-20220819204917778](https://img.zxdmy.com/2022/202208192049334.png)

### 水平拆分与垂直拆分

**水平拆分**的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。

![img](https://img.zxdmy.com/2022/202208192050519.webp)

**垂直拆分**的意思，就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。

![img](https://img.zxdmy.com/2022/202208192050609.webp)

两种**分库分表的方式**：

- 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。
- 或者是按照某个字段hash一下均匀分散，这个较为常用。

range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。

hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表

## 12、主从同步与读写分类

### 简介

主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。

因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。

### 优点

1. 通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服务器上向外提供读功能，可以动态地调整从服务器的数量，从而调整整个数据库的性能。
2. 提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据
3. 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能
4. 数据备份。一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全

### 实现原理与主从复制流程

其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

基本原理流程，是3个线程以及之间的关联

主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；

从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中；

从：sql执行线程——执行relay log中的语句；

**复制过程如下**：

![img](https://img.zxdmy.com/2022/202208192051363.jpeg)

Binary log：主数据库的二进制日志

Relay log：从服务器的中继日志

第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。

第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。

第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。

### 主从同步延时问题

MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失问题；一个是并行复制，用来 解决主从同步延时问题。

- 半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。
- 并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

## 13、MySQL优化

### MySQL 的优化方法

### SQL 慢的原因有哪些，分别怎么优化？



### 8.1 MySQL 查询缓存（query_cache）

开启查询缓存后，在同样的查询条件以及数据情况下，会直接返回缓存中的结果。

**注意：**

+ 缓存能够**提升数据库的查询性能**；
+ 缓存也**带来额外的开销**，每次查询后都要做一次缓存操作，失效后还要销毁；
+ 查询缓存的**开启要谨慎**，尤其是写密集的应用。
+ 需要执行大量相同的 SQL 语句，且不需要频繁更改表时可开启。

查看 MySQL 是否已开启缓存：

```sql
SHOW VARIABLES LIKE 'have_query_cache';
```

![image-20220722163722539](https://img.zxdmy.com/2022/202207221637476.png)

更多操作：https://blog.csdn.net/weixin_56219549/article/details/123042365

具体可以在 `/usr/my.cnf` 中，添加设置并重启MySQL开启。



## 10、MySQL对于千万级的数据库或者大表怎么处理?

第一优化你的sql和索引；

第二加缓存，memcached,redis；

第三以上都做了后，还是慢，就做主从复制或主主复制，读写分离，可以在应用层做，效率高，也可以用三方工具

第四如果以上都做了还是慢，不要想着去做切分，mysql自带分区表，先试试这个

第五如果以上都做了，那就先做垂直拆分，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统

第六才是水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key,为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；





## mysql 页断裂了解吗

##　mysql 主从复制实现

## mysql 死锁检测（有点难了，只说了mysql有死锁检测和自动释放锁，但是实际的检测是怎么做的不会，答的话应该是：老版本深度优先遍历，新版本**稀疏等待关系图**）

## 查询回表了解吗？