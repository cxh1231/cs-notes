> https://javaguide.cn/database/mysql/mysql-questions-01.html
>
> [https://www.javalearn.cn/#/doc/MySQL/面试题](https://www.javalearn.cn/#/doc/MySQL/面试题)

## 1、数据库设计的基本步骤

1. **需求分析** : 分析用户的需求，包括数据、功能和性能需求。
2. **概念结构设计** : 主要采用 E-R 模型进行设计，包括画 E-R 图。
3. **逻辑结构设计** : 通过将 E-R 图转换成表，实现从 E-R 模型到关系模型的转换。
4. **物理结构设计** : 主要是为所设计的数据库选择合适的存储结构和存取路径。
5. **数据库实施** : 包括编程、测试和试运行
6. **数据库的运行和维护** : 系统的运行与数据库的日常维护。

## 2、数据库三范式概念

> **`范式`（ Normal Form）**，是英国人 E.F.Codd（关系数据库的老祖宗）在上个世纪70年代提出关系数据库模型后总结出来的，范式是关系数据库理论的基础，也是我们在设计数据库结构过程中所要遵循的规则和指导方法。目前有迹可寻的共有8种范式，依次是：1NF，2NF，3NF，BCNF，4NF，5NF，DKNF，6NF。

通常所用到的只是前三个范式，即：**第一范式（1NF），第二范式（2NF），第三范式（3NF）。**

+ **第一范式（1NF）**：要求属性不能被继续分割，是**数据库最基本的要求**。

  + 比如下面这个表不符合 1NF，将所有属性分解为最基本的属性即可。

    <img src="https://img.zxdmy.com/2022/202207221527511.png" alt="img" style="zoom:67%;" />

+ **第二范式（2NF）**：**消除非主属性对于码的部分函数依赖** ，即在满足 1NF 的前提下，要求表必须有主键，并且没有包含在主键中的列必须完全依赖于主键，不能只依赖于主键的一部分。

  + 比如下面这个表不符合 2NF，主码为【学号，课程号】，而关系模式中存在【姓名】等属性依赖于【学号】的关系，即【姓名】等属性对【学号，课程号】存在部分函数依赖。

    <img src="https://img.zxdmy.com/2022/202207221529500.png" alt="img" style="zoom: 80%;" />

  + 将其转化为如下 2 个表，即可符合 2NF：

    + 学生信息表【学号，姓名，性别，系名，公寓名称】
    + 成绩表【学号，课程号，成绩】

  + *但是，如果一个系一栋或几栋公寓的前提下，上面这种转化方式不符合 3NF。*

+ **第三范式（3NF）**： **消除非主属性对于码的函数依赖** ，即在满足 2NF 的前提下，要求非主键列必须直接依赖于主键，不能存在传递依赖，即不能存在【非主键列 A 依赖于非主键列 B ，非主键列 B 依赖于主键】的情况。

  + 比如一个 订单表【订单ID，订单日期，客户ID，客户名称，客户地址】，其主键是【订单ID】：
    + 订单表中非主键列，均完全依赖于主键【订单ID】，符合 2NF；
    + 但非主键列中存在一种直接依赖关系，即【客户名称，客户地址】直接依赖于【客户ID】；
    + 【客户名称，客户地址】是通过【客户ID】传递依赖于主键【订单ID】，故不符合 3NF。
  + 将其转化为如下 2 个表，即可符合 3NF：
    + 订单表【订单ID，订单日期，客户ID】
    + 客户表【客户ID，客户名称，客户地址】

## 3、MySQL 语句

### 3.1 删除语句 drop、delete、truncate 的区别

|          |       delete        |           truncate           |            drop            |
| :------: | :-----------------: | :--------------------------: | :------------------------: |
|   类型   | DML（数据操纵语言） |     DDL（数据定义语言）      |            DDL             |
|   回滚   |       可回滚        |           不可回滚           |          不可回滚          |
|   操纵   |      删除数据       |           清空数据           |          丢弃数据          |
| 删除内容 | 删除全部或部分数据  | 删除全部数据，自增主键初始化 | 删除整个表，以及索引和权限 |
| 删除速度 |    慢，逐行删除     |              快              |            最快            |

> delete 不加 where 子句，作用与 truncate 类似，但主键不初始化。

### 3.2 模糊查询 % 和 * 通配符的区别

1. 作用不同

  - `*` 通配符的作用是用来匹配所有结果集。
  - `%` 通配符的作用是用来替代一个或多个字符。

2. 优先级不同

   `*` 通配符的**优先级**比 `%` 通配符高，在同一条sql语句中，优先执行。

3. 针对范围不同

  - `*` 通配符的针对范围为一条记录的**所有字段**。
  - `%` 通配符的针对范围为一条记录的**单个字段**。

### SQL 约束

- NOT NULL: 用于控制字段的内容一定不能为空（NULL）。
- UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。
- PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。
- FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。
- CHECK: 用于控制字段的值范围。

### varchar 和 char 的区别

char 是一个定长字段,假如申请了`char(10)`的空间,那么无论实际存储多少内容.该字段都占用 10 个字符,而 varchar 是变长的,也就是说申请的只是最大长度,占用的空间为实际字符长度+1,最后一个字符存储使用了多长的空间.

在检索效率上来讲,char > varchar,因此在使用中,如果确定某个字段的值的长度,可以使用 char,否则应该尽量使用 varchar.例如存储用户 MD5 加密后的密码,则应该使用 char。

### in 和 exists 的区别

MySQL中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。

如果查询的两个表大小相当，那么用in和exists差别不大。 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。 not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。

## 4、存储过程

### 简介

> **`存储过程`（Stored Procedure）**是在大型数据库系统中，一组为了完成特定功能的SQL 语句集，它存储在数据库中，**一次编译后永久有效，比单纯的SQL速度更快**，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。
>
> **`存储过程`**中可以包含 **逻辑控制语句** 和 **数据操纵语句** , 它可以接受参数 , 输出参数 , 返回单个或多个结果集以及返回值。

### 存储过程的优缺点

**存储过程的优点**：

1. 存储过程 将复杂的 SQL 语句进行封装，在复杂查询过程中提供了一个替换位置；
2. 存储过程 在创建时即编译并存储在数据库中，其**运行速度比单纯的 SQL 语句更快**；
3. 存储过程 的调用只需要提供存储过程名和必要的参数信息，可以**减少网络流量，减轻网络负担**；
4. 存储过程 可以用于应用程序代码的不同位置，**代码精简一致**；
5. 存储过程 的访问权限（不基于表）可以向不同用户**分别授权**，**数据访问的安全性高**；
6. 存储过程 的参数数据类型，可以通过 SQLParameter 类指定，提高防御；
7. 提高代码安全，方式 SQL 注入。（但未彻底解决 , 例如将数据操作语言 `DML` 附加到输入参数）
8. 存储过程 的更新，比应用程序的更改、测试、部署需要的时间和精力更少，**可维护性高**【有争议】；

**存储过程的缺点**：

1.  难以调试和拓展，更没有拓展性
2.  存储过程 将应用程序绑定到 Server，所以使用存储过程封装业务逻辑将**限制应用程序的可移植性**。

### 存储过程的基本使用

**简单存储过程实现：**

创建

```sql
create procedure GetUsers()
begin 
	select * from user; 
end;
```

调用

```sql
call GetUsers();
```

删除

```
drop procedure if exists GetUsers;
```

**带参数的存储过程实现：**

MySql 支持 IN (传递给存储过程) , OUT (从存储过程传出) 和 INOUT (对存储过程传入和传出) 类型的参数 , 存储过程的代码位于 BEGIN 和 END 语句内 , 它们是一系列 SQL 语句 , 用来检索值 , 然后保存到相应的变量 (通过指定INTO关键字) ;

创建

```sql
create procedure GetNameByID(
	in userID int,
	out userName varchar(200)
)
begin
	select name from user
	where id = userID
	into userName;
end;
```

调用

```
call GetNameByID(1, @userName);
select @userName;
```

## 5、数据库引擎

### 5.1  InnoDB 与 MyISAM 的区别

> 在大多数的情况下，直接选择使用 InnoDB 引擎都是最合适的，InnoDB 也是 MySQL 的默认存储引擎。

|          |                            InnoDB                            |                            MyISAM                            |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|   事务   |                             支持                             |                            不支持                            |
|   外键   |                             支持                             |                            不支持                            |
| 索引结构 |                            B+ 树                             |                            B+ 树                             |
| 索引数据 | **聚集索引**，数据文件和（主键）索引**绑定**，必须有主键索引，**叶子节点即为数据文件**，主键索引效率很高 | **非聚集索引**，数据文件与索引**分离**，索引保存指向数据文件的**指针** |
| 主键索引 |                            必须有                            |                             可无                             |
| 辅助索引 |      辅助索引需要两次查询，先查主键，再通过主键查询数据      |                  主键索引与辅助索引互相独立                  |
| 全文索引 |                            不支持                            |                 支持，查询效率上 MyISAM 要高                 |
|    锁    |                    支持表、行（默认）级锁                    |                          支持表级锁                          |
|  表行数  |                       不保存，全表扫描                       |                       通过一个变量保存                       |
|   压缩   |                                                              |                    表格可被压缩后进行查询                    |
| 存储文件 |                frm：表定义文件，ibd：数据文件                |        frm：表定义文件，myd：数据文件，myi：索引文件         |
| 应用场景 |            适合频繁修改以及涉及到安全性较高的应用            |                  适合查询以及插入为主的应用                  |

> 为什么 `InnoDB` 没有**行数**这个变量？
>
> 因为 InnoDB 的**事务特性**，在**同一时刻表中的行数对于不同的事务而言是不一样的**，因此count统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。

### InnoDB 事务的 ACID 特性保证方式

+ **原子性**：使用 `undo log`（**回滚日志**）来保证；
+ **持久性**：使用 `redo log` （**重做日志**）来保证；
+ **隔离性**：通过 **锁机制**、**MVCC** 等手段来保证（ 默认支持的隔离级别是  `REPEATABLE-READ` ）；
+ **一致性**：保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。

### 锁机制与 InnoDB 锁算法

**表级锁和行级锁对比：**

- **表级锁：** MySQL 中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM 和 InnoDB 引擎都支持表级锁。
- **行级锁：** MySQL 中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

**InnoDB 存储引擎的锁的算法有三种：**

- `Record lock`：记录锁，单个行记录上的锁
- `Gap lock`：间隙锁，锁定一个范围，不包括记录本身
- `Next-key lock`：record+gap 临键锁，锁定一个范围，包含记录本身

## 6、MySQL 执行过程

### 查询过程

1. 客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配
2. 查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。）
3. 语法分析（SQL 语法是否写错了）。 如何把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义。
4. 优化。是否使用索引，生成执行计划。
5. 交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。

![image-20220819200441740](https://img.zxdmy.com/2022/202208192004163.png)

更新语句执行会复杂一点。需要检查表是否有排它锁，写 binlog，刷盘，是否执行 commit。

## 7、MySQL 的锁

### 简介

当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。

保证多用户环境下保证数据库完整性和一致性。

### 数据库锁分类

#### 粒度上：

在关系型数据库中，可以**按照锁的粒度把数据库锁分**为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。

行级锁

- 行级锁是[MySQL](https://cloud.tencent.com/product/cdb?from=10680)中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。
- 开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

表级锁

- 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。
- 开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

页级锁

- 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁
- 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

#### 类别上：

从锁的类别上来讲，有共享锁和排他锁。

- 共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。
- 排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。

用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。

锁的粒度取决于具体的存储引擎，InnoDB实现了行级锁，页级锁，表级锁。

他们的加锁开销从大到小，并发能力也是从大到小。

### 乐观锁与悲观锁

数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。

- 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制
- 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。

**两种锁的使用场景**

从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。

但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。

### 死锁与解决方案

死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

常见的解决死锁的方法

1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。

2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；

3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；

如果业务处理不好可以用分布式事务锁或者使用乐观锁

### 锁的优化

- 使用较低的隔离级别
- 设计索引，尽量使用索引去访问数据，加锁更加精确，从而减少锁冲突
- 选择合理的事务大小，给记录显示加锁时，最好一次性请求足够级别的锁。列如，修改数据的话，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁
- 不同的程序访问一组表的时候，应尽量约定一个相同的顺序访问各表，对于一个表而言，尽可能的固定顺序的获取表中的行。这样大大的减少死锁的机会。
- 尽量使用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
- 不要申请超过实际需要的锁级别
- 数据查询的时候不是必要，不要使用加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能：MVCC只在committed read（读提交）和 repeatable read （可重复读）两种隔离级别
- 对于特定的事务，可以使用表锁来提高处理速度活着减少死锁的可能。

## 8、MySQL 事务

### 事务简介

事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。

事务最经典也经常被拿出来说例子就是转账了。

假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。

### 6.1 事务的 ACID 特性

> **是逻辑上的一组操作，要么都执行，要么都不执行。**

1. **原子性**（`Atomicity`） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. **一致性**（`Consistency`）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
3. **隔离性**（`Isolation`）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
4. **持久性**（`Durability`）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

### 6.2 并发事务的问题

- **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。

  - 即使用了旧数据

- **丢失修改（Lost to modify）**：当两个或多个事务更新同一行记录，会产生更新丢失现象。

  - 改了又改

- **不可重复读（Unrepeatable read）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。

  - A 读了，B 改了，A 又读

- **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

  - A 读的同时，B 添加了，导致 A 读多了

  1、脏读：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据

  2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果 不一致。

  3、幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。

  不可重复读侧重于修改，幻读侧重于新增或删除（多了或少量行），脏读是一个事务回滚影响另外一个事务。

### 6.3 事务的隔离级别与锁关系

#### 隔离级别

> 如何实现事务的隔离？
>
> https://haicoder.net/note/MySQL-interview/MySQL-interview-MySQL-trans-level.html

- **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。
- **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。
- **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
- **SERIALIZABLE(串行化)：** 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

- Read Uncommitted（读取未提交内容）

在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。

- Read Committed（读取提交内容）

这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓 的 不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一 select 可能返回不同结果。

- Repeatable Read（可重读）

这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。

- Serializable（可串行化）

通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

![image-20210822180308501](https://img.zxdmy.com/2022/202208192035617.png)

MySQL 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别

事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。

因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内容):，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）**并不会有任何性能损失。

InnoDB 存储引擎在 分布式事务 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。

#### 隔离级别与锁关系

在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突

在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁；

在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。

SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。

### 事务的两种日志

**两种日志**

innodb 事务日志包括 redo log 和 undo log。

undo log 指事务开始之前，在操作任何数据之前，首先将需操作的数据备份到一个地方。redo log 指事务中操作的任何数据，将最新的数据备份到一个地方。

事务日志的目的：实例或者介质失败，事务日志文件就能派上用场。

#### redo log

redo log 不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 redo 中。具体的落盘策略可以进行配置 。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启 MySQL 服务的时候，根据 redo log 进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。RedoLog 是为了实现事务的持久性而出现的产物。

![image-20220819203818909](https://img.zxdmy.com/2022/202208192038484.png)

#### undo log

undo log 用来回滚行记录到某个版本。事务未提交之前，Undo 保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读。是为了实现事务的原子性而出现的产物,在 MySQL innodb 存储引擎中用来实现多版本并发控制。

![image-20220819203837173](https://img.zxdmy.com/2022/202208192038621.png)

**还有一种log 是与事务无关的**：

MySQL的 `binlog` 是记录所有数据库表结构变更（例如 CREATE、ALTER TABLE）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志。binlog 不会记录 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改，但你可以通过查询通用日志来查看 MySQL 执行过的所有语句。

MySQL binlog 以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的二进制日志是事务安全型的。binlog 的主要目的是复制和恢复。

binlog 有三种格式，各有优缺点：

- **statement：** 基于 SQL 语句的模式，某些语句和函数如 UUID, LOAD DATA INFILE 等在复制过程可能导致数据不一致甚至出错。
- **row：** 基于行的模式，记录的是行的变化，很安全。但是 binlog 会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大。
- **mixed：** 混合模式，根据语句来选用是 statement 还是 row 模式。

### 事务的实现原理

事务是基于重做日志文件(redo log)和回滚日志(undo log)实现的。

每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。

每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 的反向语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。undo log 主要实现数据库的一致性。



## 9、MySQL 索引

### 索引简介

索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。

索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。而且索引是一个文件，它是要占据物理空间的。

MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。比如我们在查字典的时候，前面都有检索的拼音和偏旁、笔画等，然后找到对应字典页码，这样然后就打开字典的页数就可以知道我们要搜索的某一个key的全部值的信息了。

### 索引的优缺点

**优点** ：

- 使用索引可以大大 **加快数据的检索速度**（大大减少检索的数据量）, 这也是创建索引的 **主要原因**；
- 使用索引可以在查询过程中，**使用优化隐藏器**，提供系统性能；
- 通过创建**唯一性索引**，可以保证数据库表中每一行数据的**唯一性**。

**缺点** ：

- **时间方面：创建索引和维护索引需要耗时**。即：当对表中的数据进行增、删、改时，索引需要动态维护，会降低 SQL 的执行效率；
- **空间方面：索引需要占用物理文件存储**，也会耗费一定空间。

### 索引的底层数据结构

#### Hash 索引

基于哈希表实现，只有精确匹配索引所有列的查询才有效。

对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。

![image-20220819201418648](https://img.zxdmy.com/2022/202208192014972.png)

> **为什么MySQL 没有使用 Hash 作为索引的数据结构？**
>
> + **Hash 冲突问题**：哈希表存在哈希冲突问题；
> + 最大缺点：**Hash 索引不支持顺序和范围查询**，使得对表数据进行排序或范围查询时，索引不可用。

#### B 树索引

B-Tree 能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，**数据分布在各个节点之中**。

![image-20220819201836182](https://img.zxdmy.com/2022/202208192018448.png)

#### B\+ 树索引（实际应用）

**B\+ 树的数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址**。

![image-20220819201946478](https://img.zxdmy.com/2022/202208192019737.png)

相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。

B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。

**B+ 树的性质**：

- n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
- 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
- B+ 树中，数据对象的插入和删除仅在叶节点上进行。
- B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。

#### 为什么索引结构默认使用B+Tree

B-tree：

从两个方面来回答

- B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B(B-)树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对`IO读写次数就降低`了。
- 由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在`区间查询`的情况，所以通常B+树用于数据库索引。

Hash：

- 虽然可以快速定位，但是没有顺序，IO复杂度高；

- 基于Hash表实现，只有Memory存储引擎显式支持哈希索引 ；
- 适合**等值查询**，如=、in()、<=>，不支持范围查询 ；
- 因为不是按照索引值顺序存储的，就不能像B+Tree索引一样利用索引完成[排序](https://www.javalearn.cn/#/) ；
- Hash索引在查询等值时非常快 ；
- 因为Hash索引始终索引的**所有列的全部内容**，所以不支持部分索引列的匹配查找 ；
- 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 。

二叉树： 树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。

红黑树： 树的高度随着数据量增加而增加，IO代价高。

### 索引的分类

#### 存储结构上：

BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式

#### 应用层次上：

- 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引
- 唯一索引：索引列的值必须唯一，但允许有空值
- 联合索引（复合索引）：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并

MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。

具体原因为:

MySQL使用索引时需要索引有序，假设现在建立了"name，age，school"的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。

当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。

**最左前缀原则**就是**最左优先**，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。 mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

#### 数据的物理顺序与键值的逻辑（索引）顺序关系上：

- 聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。
- 非聚簇索引： 不是聚簇索引，就是非聚簇索引

在 InnoDB 里，索引B+ Tree的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引，即将数据存储与索引放到了一块，找到索引也就找到了数据。

而索引B+ Tree的叶子节点存储了主键的值的是非主键索引，也被称之为非聚簇索引、二级索引。

**聚簇索引与非聚簇索引的区别**：

- 非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键（行号）
- 对于InnoDB来说，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为**回表**。第一次索引一般是顺序IO，回表的操作属于随机IO。需要回表的次数越多，即随机IO次数越多，我们就越倾向于使用全表扫描 。
- 通常情况下， 主键索引（聚簇索引）查询只会查一次，而非主键索引（非聚簇索引）需要回表查询多次。当然，如果是覆盖索引的话，查一次即可
- 注意：MyISAM无论主键索引还是二级索引都是非聚簇索引，而InnoDB的主键索引是聚簇索引，二级索引是非聚簇索引。我们自己建的索引基本都是非聚簇索引。

**非聚簇索不一定会回表查询**，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。一个索引包含（覆盖）所有需要查询字段的值，被称之为"覆盖索引"。

举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行`select score from student where score > 90`的查询时，在索引的叶子节点上，已经包含了score 信息，不会再次进行回表查询。

### 索引创建

创建索引有三种方式。

1、 在执行CREATE TABLE时创建索引

```sql
CREATE TABLE user_index2 (
    id INT auto_increment PRIMARY KEY,
    first_name VARCHAR (16),
    last_name VARCHAR (16),
    id_card VARCHAR (18),
    information text,
    KEY name (first_name, last_name),
    FULLTEXT KEY (information),
    UNIQUE KEY (id_card)
);
```

2、 使用ALTER TABLE命令去增加索引。

```sql
ALTER TABLE table_name ADD INDEX index_name (column_list);
```

ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。

其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。

索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。 3、 使用CREATE INDEX命令创建。

```sql
CREATE INDEX index_name ON table_name (column_list);
```

### 前缀索引

因为可能我们索引的字段非常长，这既占内存空间，也不利于维护。所以我们就想，如果只把很长字段的前面的公共部分作为一个索引，就会产生超级加倍的效果。但是，我们需要注意，order by不支持前缀索引 。

流程是：

先计算完整列的选择性 :` select count(distinct col_1)/count(1) from table_1 `

再计算不同前缀长度的选择性 :`select count(distinct left(col_1,4))/count(1) from table_1 `

找到最优长度之后，创建前缀索引 :` create index idx_front on table_1 (col_1(4))`

### 索引下推

MySQL 5.6引入了索引下推优化。默认开启，使用SET optimizer_switch = ‘index_condition_pushdown=off’;可以将其关闭。

- 有了索引下推优化，可以在**减少回表次数**
- 在InnoDB中只针对二级索引有效

官方文档中给的例子和解释如下：

在 people_table中有一个二级索引(zipcode，lastname，address)，查询是SELECT * FROM people WHERE zipcode=’95054′ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’;

- 如果没有使用索引下推技术，则MySQL会通过zipcode=’95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断数据是否符合条件
- 如果使用了索引下推技术，则MYSQL首先会返回符合zipcode=’95054’的索引，然后根据lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。

### 索引失效

##### 1、使用!= 或者 <> 导致索引失效

##### 2、类型不一致导致的索引失效

##### 3、函数导致的索引失效

如：

```
SELECT * FROM `user` WHERE DATE(create_time) = '2020-09-03';
```

如果使用函数在索引列，这是不走索引的。

##### 4、运算符导致的索引失效

```
SELECT * FROM `user` WHERE age - 1 = 20;
```

如果你对列进行了（+，-，*，/，!）, 那么都将不会走索引。

##### 5、OR引起的索引失效

```
SELECT * FROM `user` WHERE `name` = '张三' OR height = '175';
```

OR导致索引是在特定情况下的，并不是所有的OR都是使索引失效，如果OR连接的是同一个字段，那么索引不会失效，反之索引失效。

##### 6、模糊搜索导致的索引失效

```
SELECT * FROM `user` WHERE `name` LIKE '%冰';
```

当`%`放在匹配字段前是不走索引的，放在后面才会走索引。

##### 7、NOT IN、NOT EXISTS导致索引失效

### 创建索引的注意事项

**创建原则**

1、最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

2、=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

3、尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。

4、索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。

5、尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

**注意事项**

- 选择合适的字段
  - 不为NULL的字段 , 如果需要 , 使用0 , 1 , true , false来代替
  - 被频繁查询的字段
  - 被作为条件查询的字段
  - 频繁需要排序的字段
  - 频繁连接的字段
- 被频繁更新的字段应谨慎建立索引
- 尽量考虑联合索引而非单列索引
- 尽量避免冗余索引
  - 能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引



- 非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；
- 取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；
- 索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。

### mysql 联合索引创建优化？

### MySQL 主键索引和唯一索引的区别

### mysql 索引使用



## 10、MySQL 的 MVCC（多版本并发控制）

MVCC， 即多版本并发控制。

MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。

根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。

#### 解决什么问题?

- 大多数的MYSQL事务型存储引擎,如InnoDB都不使用一种简单的行锁机制.事实上,他们都和MVCC–多版本并发控制来一起使用
- 锁机制可以控制并发操作,但是其系统开销较大,而MVCC可以在大多数情况下代替行级锁,使用MVCC,能降低其系统开销

#### 实现

通过保存数据在某个时间点的快照来实现的. 不同存储引擎的MVCC. 不同存储引擎的MVCC实现是不同的,典型的有乐观并发控制和悲观并发控制

**快照读**

如果读取的行正在执行 `DELETE` 或 `UPDATE` 操作，这时读取操作不会去等待行上锁的释放。相反地，`InnoDB` 存储引擎会去读取行的一个快照数据，对于这种读取历史数据的方式，我们叫它快照读

**锁定读**

如果执行的是下列语句，就是锁定读

- `select ... lock in share mode`

- `select ... for update`

- `insert`、`update`、`delete` 操作

  在锁定读下，读取的是数据的最新版本

### InnoDB 对 MVCC 的实现

`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改

### MVCC 的实现原理

对于 InnoDB ，聚簇索引记录中包含 3 个隐藏的列：

- ROW ID：隐藏的自增 ID，如果表没有主键，InnoDB 会自动按 ROW ID 产生一个聚集索引树。
- 事务 ID：记录最后一次修改该记录的事务 ID。
- 回滚指针：指向这条记录的上一个版本。

我们拿上面的例子，对应解释下 MVCC 的实现原理，如下图：

![image-20220819204225061](https://img.zxdmy.com/2022/202208192042463.png)

如图，首先 insert 语句向表 t1 中插入了一条数据，a 字段为 1，b 字段为 1， ROW ID 也为 1 ，事务 ID 假设为 1，回滚指针假设为 null。当执行 update t1 set b=666 where a=1 时，大致步骤如下：

- 数据库会先对满足 a=1 的行加排他锁；
- 然后将原记录复制到 undo 表空间中；
- 修改 b 字段的值为 666，修改事务 ID 为 2；
- 并通过隐藏的回滚指针指向 undo log 中的历史记录；
- 事务提交，释放前面对满足 a=1 的行所加的排他锁。

在前面实验的第 6 步中，session2 查询的结果是 session1 修改之前的记录，这个记录就是**来自 undolog** 中。

因此可以总结出 MVCC 实现的原理大致是：

InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本，这个历史版本存放在 undo log 中。如果要执行更新操作，会将原记录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事务此时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。

MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。

## 11、分库分表

### 简介

**分表**

比如你单表都几千万数据了，你确定你能扛住么？绝对不行，单表数据量太大，会极大影响你的 sql执行的性能，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。

分表就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。

**分库**

分库就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。

这就是所谓的分库分表。

![image-20220819204917778](https://img.zxdmy.com/2022/202208192049334.png)

### 水平拆分与垂直拆分

**水平拆分**的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。

![img](https://img.zxdmy.com/2022/202208192050519.webp)

**垂直拆分**的意思，就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。

![img](https://img.zxdmy.com/2022/202208192050609.webp)

两种**分库分表的方式**：

- 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。
- 或者是按照某个字段hash一下均匀分散，这个较为常用。

range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。

hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表

## 12、主从同步与读写分类

### 简介

主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。

因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。

### 优点

1. 通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服务器上向外提供读功能，可以动态地调整从服务器的数量，从而调整整个数据库的性能。
2. 提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据
3. 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能
4. 数据备份。一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全

### 实现原理与主从复制流程

其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

基本原理流程，是3个线程以及之间的关联

主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；

从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中；

从：sql执行线程——执行relay log中的语句；

**复制过程如下**：

![img](https://img.zxdmy.com/2022/202208192051363.jpeg)

Binary log：主数据库的二进制日志

Relay log：从服务器的中继日志

第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。

第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。

第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。

### 主从同步延时问题

MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失问题；一个是并行复制，用来 解决主从同步延时问题。

- 半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。
- 并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

## 13、MySQL优化

### MySQL 的优化方法

### SQL 慢的原因有哪些，分别怎么优化？



### 8.1 MySQL 查询缓存（query_cache）

开启查询缓存后，在同样的查询条件以及数据情况下，会直接返回缓存中的结果。

**注意：**

+ 缓存能够**提升数据库的查询性能**；
+ 缓存也**带来额外的开销**，每次查询后都要做一次缓存操作，失效后还要销毁；
+ 查询缓存的**开启要谨慎**，尤其是写密集的应用。
+ 需要执行大量相同的 SQL 语句，且不需要频繁更改表时可开启。

查看 MySQL 是否已开启缓存：

```sql
SHOW VARIABLES LIKE 'have_query_cache';
```

![image-20220722163722539](https://img.zxdmy.com/2022/202207221637476.png)

更多操作：https://blog.csdn.net/weixin_56219549/article/details/123042365

具体可以在 `/usr/my.cnf` 中，添加设置并重启MySQL开启。



## 10、MySQL对于千万级的数据库或者大表怎么处理?

第一优化你的sql和索引；

第二加缓存，memcached,redis；

第三以上都做了后，还是慢，就做主从复制或主主复制，读写分离，可以在应用层做，效率高，也可以用三方工具

第四如果以上都做了还是慢，不要想着去做切分，mysql自带分区表，先试试这个

第五如果以上都做了，那就先做垂直拆分，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统

第六才是水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key,为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；





## mysql 页断裂了解吗

##　mysql 主从复制实现

## mysql 死锁检测（有点难了，只说了mysql有死锁检测和自动释放锁，但是实际的检测是怎么做的不会，答的话应该是：老版本深度优先遍历，新版本**稀疏等待关系图**）

## 查询回表了解吗？